{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNVMbqD6vbohJBcrlDlhtXq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ram130849/Deep_Learning_Systems_Assignments/blob/main/TensorFlow/Sushant/DLS_Assignment_3_Part3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfQXFylNn1oF",
        "outputId": "66251713-4256-49db-ba81-a1aa6b253e0d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.56.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (4.13.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.9.24)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgr8DtU_n4JA",
        "outputId": "a38b5366-55d0-445f-d522-29e8fdf62bcb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C-vl0SVXEvC0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import librosa\n",
        "import librosa.display\n",
        "import timeit\n",
        "import os\n",
        "from IPython.display import Audio\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf\n",
        "from tensorflow.keras.layers import Conv1D,Conv2D,MaxPooling1D,MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from keras.models import Model\n",
        "import pickle\n",
        "import tarfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47g0WosLYwzH",
        "outputId": "d9c2a8a7-e100-4bf3-c629-471f667f99d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "metadata": {
        "id": "yFs-8y6FYx5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c92c11d3-5307-471c-fe3e-d3699fd27f12"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "2.301579206999918\n",
            "GPU (s):\n",
            "0.04047881100007089\n",
            "GPU speedup over CPU: 56x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) 1200 noisy speech signals (from trx0000.wav to trx1199.wav)\n",
        "#### 2) 120 clean speech signals (10sentences per speaker for 12 speakers)\n",
        "#### 3) Original Clean Speech - (from trs0000.wav to trs1199.wav)\n",
        "#### 4) Noise Sources - (from trn0000.wav to trn1199.wav)\n",
        "#### 5) Adding these clean and noise speeches we get trx speeches but since it is given in the folder, there is no need to do it"
      ],
      "metadata": {
        "id": "rlLzcu5dJg0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdLxn17UK00H",
        "outputId": "fc3c848e-dc7c-4e13-ef20-4ea8307d5ed9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_train = '/content/drive/MyDrive/DLS_Assignments/Assignment3_Data/timit-homework/tr/'\n",
        "path_validation = '/content/drive/MyDrive/DLS_Assignments/Assignment3_Data/timit-homework/v/'\n",
        "path_test = '/content/drive/MyDrive/DLS_Assignments/Assignment3_Data/timit-homework/te/'"
      ],
      "metadata": {
        "id": "CGx--XpZYa-4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/DLS_Assignments/Assignment3_Data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2FQvYb3qEXp",
        "outputId": "ba411e81-d52c-4f2c-97c1-35e83b38baf4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timit-homework\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "  x=[]\n",
        "  clean=[]\n",
        "  noise=[]\n",
        "  for file in os.listdir(path):\n",
        "    if file.startswith('trx') or file.startswith('tex') or file.startswith('vx'):\n",
        "      #if file not in x:\n",
        "        x.append(file)\n",
        "\n",
        "    elif file.startswith('trs') or file.startswith('tes') or file.startswith('vs'):\n",
        "      #if file not in clean:\n",
        "        clean.append(file)\n",
        "\n",
        "    elif file.startswith('trn') or file.startswith('ten') or file.startswith('vn'):\n",
        "      #if file not in noise:\n",
        "        noise.append(file)\n",
        "  \n",
        "  x.sort()\n",
        "  clean.sort()\n",
        "  noise.sort()\n",
        "\n",
        "  return x,clean,noise"
      ],
      "metadata": {
        "id": "K5PmohTtmK6m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Train Data:"
      ],
      "metadata": {
        "id": "mcxKAWy6sY-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, clean_train, noise_train = load_data(path_train)"
      ],
      "metadata": {
        "id": "0fA5TtD2sdqm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The size of x_train is : \",len(x_train))\n",
        "print(\"The size of clean_train is : \",len(clean_train))\n",
        "print(\"The size of noise_train is : \",len(noise_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsYeIL7-tKB7",
        "outputId": "c1c419e0-e152-4dc0-c864-4d7d229a914c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of x_train is :  1200\n",
            "The size of clean_train is :  1200\n",
            "The size of noise_train is :  1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Validation Data:"
      ],
      "metadata": {
        "id": "FRIO-kF2sxfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_val, clean_val, noise_val = load_data(path_validation)"
      ],
      "metadata": {
        "id": "QdtOS0aEs13O"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The size of x_val is : \",len(x_val))\n",
        "print(\"The size of clean_val is : \",len(clean_val))\n",
        "print(\"The size of noise_val is : \",len(noise_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWp3xFZFtpxU",
        "outputId": "aefff05d-7e57-4a89-ea29-2c90318511cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of x_val is :  1200\n",
            "The size of clean_val is :  1200\n",
            "The size of noise_val is :  1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Test Data:"
      ],
      "metadata": {
        "id": "oRWADzIas8y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, clean_test, noise_test = load_data(path_test)"
      ],
      "metadata": {
        "id": "vvxPlIU2tAZ-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The size of x_test is : \",len(x_test))\n",
        "print(\"The size of clean_test is : \",len(clean_test))\n",
        "print(\"The size of noise_test is : \",len(noise_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_eXVv1at5Ap",
        "outputId": "2761f927-7373-4895-d5ce-492a7bb80b78"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of x_test is :  400\n",
            "The size of clean_test is :  0\n",
            "The size of noise_test is :  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_stft(path,input):\n",
        "  data_abs=[]\n",
        "  for i in input:\n",
        "    s, sr = librosa.load(path+i, sr=None)\n",
        "    S = librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "    pad = np.zeros((513, 178))\n",
        "    pad[:, :S.shape[1]] = S\n",
        "    pad=pad.T\n",
        "    pad_abs = np.abs(pad)\n",
        "    data_abs.append(pad_abs)\n",
        "  return data_abs"
      ],
      "metadata": {
        "id": "UKCQ30sYZTKg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing STFT for Training Data"
      ],
      "metadata": {
        "id": "dL-8axhe5Xom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_stft = compute_stft(path_train,x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JczFSiaRv5k4",
        "outputId": "a3f615ef-cec7-414e-f625-5745694c8b5f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of x_train_stft is : \",x_train_stft[0].shape)\n",
        "print(len(x_train_stft))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-ibF94NP1oi",
        "outputId": "9bd0e203-0b0a-4f88-859d-54056b079143"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train_stft is :  (178, 513)\n",
            "1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_train_stft = compute_stft(path_train,clean_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxCL6LOg5n8-",
        "outputId": "a1290bbd-a561-449c-cf96-9063f8738aa5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(clean_train_stft))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgbytcyMRR-V",
        "outputId": "f18a1779-36ee-424b-cf15-bfaca8bc1fd8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_train_stft = compute_stft(path_train,noise_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GhXBpyQ5oCq",
        "outputId": "98c7e5c3-e4eb-476c-f72c-a6cd8a91af19"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing STFT for Validation Data"
      ],
      "metadata": {
        "id": "gPeBltSeFAqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_val_stft = compute_stft(path_validation,x_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArGrVbbZE_4q",
        "outputId": "19ef927e-5f1e-43cc-f844-e470e9f94583"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_val_stft = compute_stft(path_validation,clean_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLCHNbSaFI2M",
        "outputId": "519d04cc-34b1-4bc5-d595-da1b2a6a9eec"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_val_stft = compute_stft(path_validation,noise_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V26YIoV7FLCe",
        "outputId": "9cc84975-b5aa-497b-ef4e-6ab4c372007c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating IBM Matrix for Training Set"
      ],
      "metadata": {
        "id": "TfGmJ8WO7rp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ibm_train = [(clean_train_stft[i] > noise_train_stft[i]).astype(int) for i in range(len(clean_train_stft))]"
      ],
      "metadata": {
        "id": "eFoKHjRwQ-XW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ibm_train = np.stack(ibm_train)\n",
        "noise_train_new = np.stack(noise_train_stft)"
      ],
      "metadata": {
        "id": "YaXt1feVRvb7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating IBM Matrix for Validation Set"
      ],
      "metadata": {
        "id": "PM1xYjKcS6M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ibm_val = [(clean_val_stft[i] > noise_val_stft[i]).astype(int) for i in range(len(clean_val_stft))]"
      ],
      "metadata": {
        "id": "dbC04vQeSmUQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ibm_val = np.stack(ibm_val)\n",
        "noise_val_new = np.stack(noise_val_stft)"
      ],
      "metadata": {
        "id": "y5yC8IxCTVOA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ibm_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq-Cx1kbTwRn",
        "outputId": "c1afa289-c328-4130-d8c5-8df5681fc1f5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 178, 513)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential();\n",
        "model.add(layers.GRU(513, return_sequences=True))\n",
        "model.add(layers.Dropout(rate = 0.2))\n",
        "model.add(layers.GRU(513, return_sequences=True))\n",
        "model.add(layers.Dropout(rate = 0.2))\n",
        "model.add(layers.Dense(513, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "RSyRMVr-T8PX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.BinaryCrossentropy())"
      ],
      "metadata": {
        "id": "M_CrmgRyVCHH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model.fit(noise_train_new, ibm_train, epochs=20, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osUOuP-vVXth",
        "outputId": "0de53732-339d-4369-d3a0-a88f310a6e31"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "120/120 [==============================] - 9s 41ms/step - loss: 0.4959\n",
            "Epoch 2/20\n",
            "120/120 [==============================] - 5s 40ms/step - loss: 0.3698\n",
            "Epoch 3/20\n",
            "120/120 [==============================] - 5s 40ms/step - loss: 0.3247\n",
            "Epoch 4/20\n",
            "120/120 [==============================] - 5s 40ms/step - loss: 0.3150\n",
            "Epoch 5/20\n",
            "120/120 [==============================] - 5s 41ms/step - loss: 0.3104\n",
            "Epoch 6/20\n",
            "120/120 [==============================] - 5s 41ms/step - loss: 0.3046\n",
            "Epoch 7/20\n",
            "120/120 [==============================] - 5s 41ms/step - loss: 0.3029\n",
            "Epoch 8/20\n",
            "120/120 [==============================] - 5s 41ms/step - loss: 0.2969\n",
            "Epoch 9/20\n",
            "120/120 [==============================] - 5s 41ms/step - loss: 0.2939\n",
            "Epoch 10/20\n",
            "120/120 [==============================] - 5s 41ms/step - loss: 0.3030\n",
            "Epoch 11/20\n",
            "120/120 [==============================] - 5s 41ms/step - loss: 0.2907\n",
            "Epoch 12/20\n",
            "120/120 [==============================] - 5s 41ms/step - loss: 0.2890\n",
            "Epoch 13/20\n",
            "120/120 [==============================] - 5s 40ms/step - loss: 0.2870\n",
            "Epoch 14/20\n",
            "120/120 [==============================] - 5s 41ms/step - loss: 0.2883\n",
            "Epoch 15/20\n",
            "120/120 [==============================] - 5s 40ms/step - loss: 0.2873\n",
            "Epoch 16/20\n",
            "120/120 [==============================] - 5s 40ms/step - loss: 0.2858\n",
            "Epoch 17/20\n",
            "120/120 [==============================] - 5s 40ms/step - loss: 0.2951\n",
            "Epoch 18/20\n",
            "120/120 [==============================] - 5s 40ms/step - loss: 0.3099\n",
            "Epoch 19/20\n",
            "120/120 [==============================] - 5s 40ms/step - loss: 0.2902\n",
            "Epoch 20/20\n",
            "120/120 [==============================] - 5s 41ms/step - loss: 0.2842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/gdrive/MyDrive/DLS_Assignments/Models/assign3_part3_model.h5'\n",
        "model.save(model_path)"
      ],
      "metadata": {
        "id": "Op04_ixDVbkW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WxSGVP_9eTNh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}