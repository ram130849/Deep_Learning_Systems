{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ram130849/Deep_Learning_Systems_Assignments/blob/main/TensorFlow/Sushant/DLS_Assignment4_Part3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSPMumjepCVI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "# import tensorflow_addons as tfa\n",
        "# import librosa\n",
        "# import librosa.display\n",
        "import timeit\n",
        "from IPython.display import Audio\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Conv1D,Conv2D,MaxPooling1D,MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from keras.models import Model\n",
        "import pickle\n",
        "import tarfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJfNanXTpJB_",
        "outputId": "11d20230-1726-48ad-9a64-f6170803331c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtXF1lmw3sxT",
        "outputId": "e95d7e6b-d3e3-4a08-8f2e-fe1f76ea0111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.186999797999988\n",
            "GPU (s):\n",
            "0.04028142600000706\n",
            "GPU speedup over CPU: 79x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the MNIST Dataset"
      ],
      "metadata": {
        "id": "ICT2Zdv-4OUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist"
      ],
      "metadata": {
        "id": "LCVExLwS34P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels) , (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq-aBFg_36x2",
        "outputId": "06ac3b9f-632f-4038-c6f9-286ce66cc81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets look at the training data\n",
        "print(\"Training Images Shape: \",train_images.shape)\n",
        "print(\"Training Labels: \",train_labels)\n",
        "\n",
        "\n",
        "#Lets look at the testing data\n",
        "print(\"Testing Images Shape: \",test_images.shape)\n",
        "print(\"Testing Labels: \",test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP6B-ir339Q3",
        "outputId": "2e24f67b-4225-45a5-e5a3-ebfc079582ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Images Shape:  (60000, 28, 28)\n",
            "Training Labels:  [5 0 4 ... 5 6 8]\n",
            "Testing Images Shape:  (10000, 28, 28)\n",
            "Testing Labels:  [7 2 1 ... 4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalizing the Images"
      ],
      "metadata": {
        "id": "_nU_SUUv4SMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        "train_images/=255\n",
        "test_images/=255"
      ],
      "metadata": {
        "id": "M0j1YMzU3_VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Model from Part 1"
      ],
      "metadata": {
        "id": "oQs5c61F4VS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w08IlP3d4CAV",
        "outputId": "04faf4b1-864c-4c6e-df1a-c23c77f61ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/DLS_Assignments/Models/assign4_part1_baseline.h5'"
      ],
      "metadata": {
        "id": "RBfppEjE4EHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "jMglWdUQ4IY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = baseline.evaluate(test_images , test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_Fa35ww4JBI",
        "outputId": "1340e037-29e5-4a20-b1c6-cd706356ee2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1257 - sparse_categorical_accuracy: 0.9856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = baseline.get_layer(index=1).get_weights()[0]\n",
        "W2 = baseline.get_layer(index=2).get_weights()[0]\n",
        "W3 = baseline.get_layer(index=3).get_weights()[0]\n",
        "W4 = baseline.get_layer(index=4).get_weights()[0]\n",
        "W5 = baseline.get_layer(index=5).get_weights()[0]\n",
        "\n",
        "\n",
        "B1 = baseline.get_layer(index=1).get_weights()[1]\n",
        "B2 = baseline.get_layer(index=2).get_weights()[1]\n",
        "B3 = baseline.get_layer(index=3).get_weights()[1]\n",
        "B4 = baseline.get_layer(index=4).get_weights()[1]\n",
        "B5 = baseline.get_layer(index=5).get_weights()[1]"
      ],
      "metadata": {
        "id": "NHOk1uObPcXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Model"
      ],
      "metadata": {
        "id": "frmpPlvAQpgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.custom_gradient\n",
        "def customgrad(weight):\n",
        "  s_1 , U_1, v_1 = tf.linalg.svd(weight)\n",
        "  S_1 = tf.linalg.diag(s_1)\n",
        "\n",
        "  V_1 = tf.transpose(v_1)\n",
        "\n",
        "  W = tf.matmul(tf.matmul(U_1[:,:20], S_1[:20,:20]), V_1[:20,:])\n",
        "\n",
        "    #backprop\n",
        "  def grad(dy):\n",
        "    gradient = dy\n",
        "    return gradient\n",
        "\n",
        "  return W, grad\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CustomDense(Layer):\n",
        "  def __init__(self, units, activation,W,B):\n",
        "        super(CustomDense, self).__init__()\n",
        "        self.units = units\n",
        "        W = tf.Variable(W, name='Weights')\n",
        "        B = tf.Variable(B, name='Biases')\n",
        "        self.w = W\n",
        "        self.b = B\n",
        "        self.activation=activation\n",
        "\n",
        "\n",
        "  # def weight_biases(self, input_shape,W,B):\n",
        "  #       #w_init = tf.random_normal_initializer()\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "        W_svd = customgrad(self.w)\n",
        "        out = tf.matmul(inputs,W_svd) + self.b\n",
        "        return self.activation(out)"
      ],
      "metadata": {
        "id": "-QGGqI56Vka7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    CustomDense(1024,tf.nn.relu,W1,B1),\n",
        "    CustomDense(1024,tf.nn.relu,W2,B2),\n",
        "    CustomDense(1024,tf.nn.relu,W3,B3),\n",
        "    CustomDense(1024,tf.nn.relu,W4,B4),\n",
        "    CustomDense(1024,tf.nn.relu,W5,B5),\n",
        "    layers.Dense(10, name='output' ,activation='softmax')\n",
        "])\n",
        "\n",
        "print(model_3.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y12ZYlYQEmGQ",
        "outputId": "67285a6a-a6ea-48cb-fac2-1d51096a3c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " custom_dense_35 (CustomDens  (None, 1024)             803840    \n",
            " e)                                                              \n",
            "                                                                 \n",
            " custom_dense_36 (CustomDens  (None, 1024)             1049600   \n",
            " e)                                                              \n",
            "                                                                 \n",
            " custom_dense_37 (CustomDens  (None, 1024)             1049600   \n",
            " e)                                                              \n",
            "                                                                 \n",
            " custom_dense_38 (CustomDens  (None, 1024)             1049600   \n",
            " e)                                                              \n",
            "                                                                 \n",
            " custom_dense_39 (CustomDens  (None, 1024)             1049600   \n",
            " e)                                                              \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,012,490\n",
            "Trainable params: 5,012,490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=['accuracy'])\n",
        "\n",
        "history_3 = model_3.fit(train_images, train_labels, batch_size=512, epochs=10,verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLfztU5SWBrC",
        "outputId": "c86e24c0-2fd9-4e5d-d745-48575d178658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "118/118 [==============================] - 342s 3s/step - loss: 0.3432 - accuracy: 0.9054\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 338s 3s/step - loss: 0.0867 - accuracy: 0.9768\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 337s 3s/step - loss: 0.0676 - accuracy: 0.9806\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 337s 3s/step - loss: 0.0537 - accuracy: 0.9844\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 337s 3s/step - loss: 0.0538 - accuracy: 0.9839\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 337s 3s/step - loss: 0.0527 - accuracy: 0.9843\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 337s 3s/step - loss: 0.0512 - accuracy: 0.9847\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 337s 3s/step - loss: 0.0475 - accuracy: 0.9850\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 337s 3s/step - loss: 0.0467 - accuracy: 0.9854\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 336s 3s/step - loss: 0.0524 - accuracy: 0.9841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model_3.evaluate(test_images , test_labels)"
      ],
      "metadata": {
        "id": "lhEwsbZKudL8",
        "outputId": "058db624-dde8-4286-bfd4-897a3d4e6ce5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 894s 3s/step - loss: 0.1040 - accuracy: 0.9743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fou3o2wZ9ufh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}