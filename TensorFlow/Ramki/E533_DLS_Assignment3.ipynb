{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmGPk2WsNxObYSoBGBOF6v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ram130849/Deep_Learning_Systems_Assignments/blob/main/TensorFlow/Ramki/E533_DLS_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install IPython\n",
        "!pip install librosa"
      ],
      "metadata": {
        "id": "IN4WsmbMUmTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2433ae8e-0978-4dc3-8c4c-ddccc48e1954"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (7.9.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython) (57.4.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 20.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->IPython) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython) (0.7.0)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.56.3)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (4.13.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nWR2IVz5E9lH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292fc82b-a69c-49b4-deba-fbc00a51c2fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from IPython.display import Audio\n",
        "import librosa\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from librosa.core import stft,istft\n",
        "from tensorflow.keras.layers import GRU,Dropout\n",
        "from tensorflow.keras.layers import Conv1D,Conv2D,MaxPooling2D,Dropout,Dense,Flatten,BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import soundfile as sf\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: Data Augmentation"
      ],
      "metadata": {
        "id": "vFIobnUYYaVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = tf.keras.datasets.cifar10"
      ],
      "metadata": {
        "id": "W1XFUrl3YVSd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "_anP3TMgYVeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14cadee2-3fdc-4dbb-d55c-8d636f9bc5ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=1)\n",
        " print(X_train.shape)\n",
        " print(X_val.shape)\n",
        " print(Y_train.shape)\n",
        " print(Y_val.shape)"
      ],
      "metadata": {
        "id": "u7C4salRYVlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b20fd6-ad8b-4b39-db7b-35b11a2527af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45000, 32, 32, 3)\n",
            "(5000, 32, 32, 3)\n",
            "(45000, 1)\n",
            "(5000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_tensor(tensor): \n",
        "    tensor = tf.math.divide(\n",
        "          tf.subtract(\n",
        "              tensor, \n",
        "              tf.reduce_min(tensor)\n",
        "          ), \n",
        "          tf.subtract(\n",
        "              tf.reduce_max(tensor), \n",
        "              tf.reduce_min(tensor)\n",
        "          )\n",
        "        )\n",
        "    return 2*tensor-1"
      ],
      "metadata": {
        "id": "oZ7-Jn95kVE7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_n2, X_val_n2 = X_train/255.0, X_val/ 255.0"
      ],
      "metadata": {
        "id": "7O6TTOFrYV42"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train, Y_val = Y_train.flatten(), Y_val.flatten()\n",
        "layer = tf.keras.layers.Normalization(mean=0, variance=1)\n",
        "X_train_n1 = normalize_tensor(X_train)\n",
        "X_val_n1 = normalize_tensor(X_val)"
      ],
      "metadata": {
        "id": "arVje6TDeKA9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "he_initializer = tf.keras.initializers.HeUniform(seed=None)"
      ],
      "metadata": {
        "id": "SCMUEh7dvYq5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(Conv2D(10, (5, 5), strides=(1,1), activation='relu', input_shape=(32, 32, 3),kernel_initializer=he_initializer))\n",
        "model.add(MaxPooling2D((2, 2),strides=(2,2)))\n",
        "model.add(Conv2D(10, (5, 5), activation='relu',kernel_initializer=he_initializer))\n",
        "model.add(MaxPooling2D((2, 2),strides=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=20,activation='relu',kernel_initializer=he_initializer))\n",
        "model.add(Dense(units=10,activation='softmax',kernel_initializer=he_initializer))"
      ],
      "metadata": {
        "id": "zqaeA4fOYV_J"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=adam,loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hizhzXcyYWEP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit(X_train_n1, Y_train, validation_data=(X_val_n1, Y_val), batch_size=256, epochs=150)"
      ],
      "metadata": {
        "id": "H_uuXREjYWI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91d109a7-f1d3-4d9a-8878-74660d94d88d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 2.0114 - accuracy: 0.2582 - val_loss: 1.6965 - val_accuracy: 0.3752\n",
            "Epoch 2/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5875 - accuracy: 0.4270 - val_loss: 1.5260 - val_accuracy: 0.4444\n",
            "Epoch 3/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4446 - accuracy: 0.4827 - val_loss: 1.4128 - val_accuracy: 0.4954\n",
            "Epoch 4/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 1.3785 - accuracy: 0.5065 - val_loss: 1.3608 - val_accuracy: 0.5102\n",
            "Epoch 5/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3321 - accuracy: 0.5268 - val_loss: 1.3296 - val_accuracy: 0.5196\n",
            "Epoch 6/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2956 - accuracy: 0.5390 - val_loss: 1.2860 - val_accuracy: 0.5420\n",
            "Epoch 7/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2660 - accuracy: 0.5519 - val_loss: 1.2636 - val_accuracy: 0.5502\n",
            "Epoch 8/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2372 - accuracy: 0.5633 - val_loss: 1.2596 - val_accuracy: 0.5516\n",
            "Epoch 9/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2081 - accuracy: 0.5750 - val_loss: 1.2308 - val_accuracy: 0.5616\n",
            "Epoch 10/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 1.1903 - accuracy: 0.5811 - val_loss: 1.2225 - val_accuracy: 0.5702\n",
            "Epoch 11/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1742 - accuracy: 0.5858 - val_loss: 1.2221 - val_accuracy: 0.5676\n",
            "Epoch 12/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 1.1572 - accuracy: 0.5933 - val_loss: 1.1856 - val_accuracy: 0.5796\n",
            "Epoch 13/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1390 - accuracy: 0.6015 - val_loss: 1.1908 - val_accuracy: 0.5834\n",
            "Epoch 14/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1285 - accuracy: 0.6046 - val_loss: 1.1567 - val_accuracy: 0.5864\n",
            "Epoch 15/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1115 - accuracy: 0.6102 - val_loss: 1.1550 - val_accuracy: 0.5940\n",
            "Epoch 16/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1018 - accuracy: 0.6146 - val_loss: 1.1410 - val_accuracy: 0.5970\n",
            "Epoch 17/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 1.0926 - accuracy: 0.6185 - val_loss: 1.1406 - val_accuracy: 0.5948\n",
            "Epoch 18/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0814 - accuracy: 0.6233 - val_loss: 1.1665 - val_accuracy: 0.5934\n",
            "Epoch 19/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0731 - accuracy: 0.6253 - val_loss: 1.1148 - val_accuracy: 0.6072\n",
            "Epoch 20/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0668 - accuracy: 0.6267 - val_loss: 1.1200 - val_accuracy: 0.6032\n",
            "Epoch 21/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0575 - accuracy: 0.6308 - val_loss: 1.1129 - val_accuracy: 0.6086\n",
            "Epoch 22/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0509 - accuracy: 0.6334 - val_loss: 1.1241 - val_accuracy: 0.6032\n",
            "Epoch 23/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0483 - accuracy: 0.6341 - val_loss: 1.0983 - val_accuracy: 0.6138\n",
            "Epoch 24/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0378 - accuracy: 0.6392 - val_loss: 1.0975 - val_accuracy: 0.6150\n",
            "Epoch 25/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0304 - accuracy: 0.6409 - val_loss: 1.0914 - val_accuracy: 0.6210\n",
            "Epoch 26/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0244 - accuracy: 0.6418 - val_loss: 1.0821 - val_accuracy: 0.6252\n",
            "Epoch 27/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0204 - accuracy: 0.6448 - val_loss: 1.0834 - val_accuracy: 0.6178\n",
            "Epoch 28/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0201 - accuracy: 0.6442 - val_loss: 1.0939 - val_accuracy: 0.6138\n",
            "Epoch 29/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0102 - accuracy: 0.6488 - val_loss: 1.0871 - val_accuracy: 0.6178\n",
            "Epoch 30/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0089 - accuracy: 0.6490 - val_loss: 1.0825 - val_accuracy: 0.6202\n",
            "Epoch 31/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.6529 - val_loss: 1.0789 - val_accuracy: 0.6222\n",
            "Epoch 32/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0023 - accuracy: 0.6490 - val_loss: 1.0793 - val_accuracy: 0.6248\n",
            "Epoch 33/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9952 - accuracy: 0.6556 - val_loss: 1.0922 - val_accuracy: 0.6190\n",
            "Epoch 34/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9908 - accuracy: 0.6544 - val_loss: 1.0789 - val_accuracy: 0.6260\n",
            "Epoch 35/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9854 - accuracy: 0.6575 - val_loss: 1.0595 - val_accuracy: 0.6290\n",
            "Epoch 36/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9818 - accuracy: 0.6584 - val_loss: 1.0740 - val_accuracy: 0.6242\n",
            "Epoch 37/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9840 - accuracy: 0.6580 - val_loss: 1.0575 - val_accuracy: 0.6312\n",
            "Epoch 38/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9787 - accuracy: 0.6600 - val_loss: 1.0788 - val_accuracy: 0.6260\n",
            "Epoch 39/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9781 - accuracy: 0.6620 - val_loss: 1.0629 - val_accuracy: 0.6290\n",
            "Epoch 40/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9732 - accuracy: 0.6612 - val_loss: 1.0551 - val_accuracy: 0.6326\n",
            "Epoch 41/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9693 - accuracy: 0.6614 - val_loss: 1.0555 - val_accuracy: 0.6372\n",
            "Epoch 42/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9634 - accuracy: 0.6651 - val_loss: 1.0566 - val_accuracy: 0.6322\n",
            "Epoch 43/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9639 - accuracy: 0.6646 - val_loss: 1.0708 - val_accuracy: 0.6250\n",
            "Epoch 44/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9577 - accuracy: 0.6669 - val_loss: 1.0883 - val_accuracy: 0.6212\n",
            "Epoch 45/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9560 - accuracy: 0.6676 - val_loss: 1.0612 - val_accuracy: 0.6312\n",
            "Epoch 46/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9567 - accuracy: 0.6668 - val_loss: 1.0638 - val_accuracy: 0.6282\n",
            "Epoch 47/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9526 - accuracy: 0.6694 - val_loss: 1.0959 - val_accuracy: 0.6276\n",
            "Epoch 48/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9514 - accuracy: 0.6675 - val_loss: 1.0700 - val_accuracy: 0.6282\n",
            "Epoch 49/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9446 - accuracy: 0.6705 - val_loss: 1.0510 - val_accuracy: 0.6334\n",
            "Epoch 50/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9469 - accuracy: 0.6715 - val_loss: 1.0634 - val_accuracy: 0.6278\n",
            "Epoch 51/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9411 - accuracy: 0.6731 - val_loss: 1.0492 - val_accuracy: 0.6382\n",
            "Epoch 52/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9414 - accuracy: 0.6711 - val_loss: 1.0720 - val_accuracy: 0.6284\n",
            "Epoch 53/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9387 - accuracy: 0.6722 - val_loss: 1.0481 - val_accuracy: 0.6328\n",
            "Epoch 54/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9348 - accuracy: 0.6760 - val_loss: 1.0555 - val_accuracy: 0.6388\n",
            "Epoch 55/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9340 - accuracy: 0.6749 - val_loss: 1.0623 - val_accuracy: 0.6344\n",
            "Epoch 56/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9325 - accuracy: 0.6760 - val_loss: 1.0581 - val_accuracy: 0.6388\n",
            "Epoch 57/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9243 - accuracy: 0.6797 - val_loss: 1.0427 - val_accuracy: 0.6362\n",
            "Epoch 58/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9264 - accuracy: 0.6786 - val_loss: 1.0509 - val_accuracy: 0.6384\n",
            "Epoch 59/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9248 - accuracy: 0.6792 - val_loss: 1.0456 - val_accuracy: 0.6358\n",
            "Epoch 60/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9246 - accuracy: 0.6776 - val_loss: 1.0436 - val_accuracy: 0.6418\n",
            "Epoch 61/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9219 - accuracy: 0.6793 - val_loss: 1.0568 - val_accuracy: 0.6316\n",
            "Epoch 62/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9205 - accuracy: 0.6810 - val_loss: 1.0616 - val_accuracy: 0.6376\n",
            "Epoch 63/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9173 - accuracy: 0.6801 - val_loss: 1.0485 - val_accuracy: 0.6384\n",
            "Epoch 64/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9176 - accuracy: 0.6810 - val_loss: 1.0531 - val_accuracy: 0.6418\n",
            "Epoch 65/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.9192 - accuracy: 0.6801 - val_loss: 1.0493 - val_accuracy: 0.6354\n",
            "Epoch 66/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.9106 - accuracy: 0.6836 - val_loss: 1.0442 - val_accuracy: 0.6420\n",
            "Epoch 67/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.9113 - accuracy: 0.6821 - val_loss: 1.0419 - val_accuracy: 0.6444\n",
            "Epoch 68/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.9089 - accuracy: 0.6844 - val_loss: 1.0315 - val_accuracy: 0.6442\n",
            "Epoch 69/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.9067 - accuracy: 0.6843 - val_loss: 1.0405 - val_accuracy: 0.6424\n",
            "Epoch 70/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9081 - accuracy: 0.6830 - val_loss: 1.0447 - val_accuracy: 0.6392\n",
            "Epoch 71/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9046 - accuracy: 0.6870 - val_loss: 1.0504 - val_accuracy: 0.6390\n",
            "Epoch 72/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9041 - accuracy: 0.6851 - val_loss: 1.0418 - val_accuracy: 0.6436\n",
            "Epoch 73/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9022 - accuracy: 0.6861 - val_loss: 1.0382 - val_accuracy: 0.6416\n",
            "Epoch 74/150\n",
            "176/176 [==============================] - 1s 9ms/step - loss: 0.9044 - accuracy: 0.6838 - val_loss: 1.0393 - val_accuracy: 0.6442\n",
            "Epoch 75/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8975 - accuracy: 0.6877 - val_loss: 1.0531 - val_accuracy: 0.6402\n",
            "Epoch 76/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8972 - accuracy: 0.6864 - val_loss: 1.0539 - val_accuracy: 0.6372\n",
            "Epoch 77/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8986 - accuracy: 0.6875 - val_loss: 1.0365 - val_accuracy: 0.6474\n",
            "Epoch 78/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8931 - accuracy: 0.6883 - val_loss: 1.0519 - val_accuracy: 0.6458\n",
            "Epoch 79/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8963 - accuracy: 0.6880 - val_loss: 1.0324 - val_accuracy: 0.6454\n",
            "Epoch 80/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8953 - accuracy: 0.6868 - val_loss: 1.0786 - val_accuracy: 0.6364\n",
            "Epoch 81/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8926 - accuracy: 0.6898 - val_loss: 1.0418 - val_accuracy: 0.6410\n",
            "Epoch 82/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8891 - accuracy: 0.6904 - val_loss: 1.0413 - val_accuracy: 0.6426\n",
            "Epoch 83/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8929 - accuracy: 0.6870 - val_loss: 1.0464 - val_accuracy: 0.6394\n",
            "Epoch 84/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8870 - accuracy: 0.6893 - val_loss: 1.0405 - val_accuracy: 0.6394\n",
            "Epoch 85/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8881 - accuracy: 0.6903 - val_loss: 1.0423 - val_accuracy: 0.6446\n",
            "Epoch 86/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.8853 - accuracy: 0.6895 - val_loss: 1.0457 - val_accuracy: 0.6422\n",
            "Epoch 87/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.8834 - accuracy: 0.6911 - val_loss: 1.0384 - val_accuracy: 0.6438\n",
            "Epoch 88/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.8797 - accuracy: 0.6931 - val_loss: 1.0472 - val_accuracy: 0.6438\n",
            "Epoch 89/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.8816 - accuracy: 0.6933 - val_loss: 1.0266 - val_accuracy: 0.6496\n",
            "Epoch 90/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.8884 - accuracy: 0.6879 - val_loss: 1.0405 - val_accuracy: 0.6420\n",
            "Epoch 91/150\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.8798 - accuracy: 0.6923 - val_loss: 1.0358 - val_accuracy: 0.6474\n",
            "Epoch 92/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.8763 - accuracy: 0.6946 - val_loss: 1.0299 - val_accuracy: 0.6490\n",
            "Epoch 93/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.8762 - accuracy: 0.6948 - val_loss: 1.0394 - val_accuracy: 0.6406\n",
            "Epoch 94/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.8795 - accuracy: 0.6948 - val_loss: 1.0670 - val_accuracy: 0.6324\n",
            "Epoch 95/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.8747 - accuracy: 0.6944 - val_loss: 1.0346 - val_accuracy: 0.6470\n",
            "Epoch 96/150\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.8739 - accuracy: 0.6951 - val_loss: 1.0394 - val_accuracy: 0.6416\n",
            "Epoch 97/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8743 - accuracy: 0.6933 - val_loss: 1.0525 - val_accuracy: 0.6376\n",
            "Epoch 98/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8728 - accuracy: 0.6948 - val_loss: 1.0614 - val_accuracy: 0.6336\n",
            "Epoch 99/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8747 - accuracy: 0.6935 - val_loss: 1.0447 - val_accuracy: 0.6440\n",
            "Epoch 100/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8703 - accuracy: 0.6985 - val_loss: 1.0493 - val_accuracy: 0.6472\n",
            "Epoch 101/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8696 - accuracy: 0.6972 - val_loss: 1.0348 - val_accuracy: 0.6424\n",
            "Epoch 102/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8675 - accuracy: 0.6970 - val_loss: 1.0591 - val_accuracy: 0.6322\n",
            "Epoch 103/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8677 - accuracy: 0.6963 - val_loss: 1.0374 - val_accuracy: 0.6382\n",
            "Epoch 104/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8674 - accuracy: 0.6962 - val_loss: 1.0546 - val_accuracy: 0.6352\n",
            "Epoch 105/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8641 - accuracy: 0.6965 - val_loss: 1.0471 - val_accuracy: 0.6372\n",
            "Epoch 106/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8643 - accuracy: 0.6979 - val_loss: 1.0435 - val_accuracy: 0.6412\n",
            "Epoch 107/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8643 - accuracy: 0.6977 - val_loss: 1.0308 - val_accuracy: 0.6448\n",
            "Epoch 108/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8632 - accuracy: 0.6970 - val_loss: 1.0528 - val_accuracy: 0.6398\n",
            "Epoch 109/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8650 - accuracy: 0.6981 - val_loss: 1.0302 - val_accuracy: 0.6472\n",
            "Epoch 110/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8620 - accuracy: 0.6996 - val_loss: 1.0490 - val_accuracy: 0.6380\n",
            "Epoch 111/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8595 - accuracy: 0.6997 - val_loss: 1.0397 - val_accuracy: 0.6460\n",
            "Epoch 112/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8602 - accuracy: 0.6995 - val_loss: 1.0301 - val_accuracy: 0.6430\n",
            "Epoch 113/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8606 - accuracy: 0.6981 - val_loss: 1.0465 - val_accuracy: 0.6456\n",
            "Epoch 114/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8553 - accuracy: 0.7007 - val_loss: 1.0263 - val_accuracy: 0.6460\n",
            "Epoch 115/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8569 - accuracy: 0.7012 - val_loss: 1.0344 - val_accuracy: 0.6466\n",
            "Epoch 116/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8554 - accuracy: 0.7014 - val_loss: 1.0252 - val_accuracy: 0.6468\n",
            "Epoch 117/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8523 - accuracy: 0.7016 - val_loss: 1.0236 - val_accuracy: 0.6486\n",
            "Epoch 118/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8539 - accuracy: 0.7036 - val_loss: 1.0191 - val_accuracy: 0.6500\n",
            "Epoch 119/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8540 - accuracy: 0.7026 - val_loss: 1.0367 - val_accuracy: 0.6468\n",
            "Epoch 120/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8511 - accuracy: 0.7019 - val_loss: 1.0479 - val_accuracy: 0.6466\n",
            "Epoch 121/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8493 - accuracy: 0.7032 - val_loss: 1.0359 - val_accuracy: 0.6506\n",
            "Epoch 122/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8485 - accuracy: 0.7016 - val_loss: 1.0424 - val_accuracy: 0.6448\n",
            "Epoch 123/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8493 - accuracy: 0.7014 - val_loss: 1.0320 - val_accuracy: 0.6490\n",
            "Epoch 124/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8494 - accuracy: 0.7035 - val_loss: 1.0373 - val_accuracy: 0.6432\n",
            "Epoch 125/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8518 - accuracy: 0.7019 - val_loss: 1.0503 - val_accuracy: 0.6410\n",
            "Epoch 126/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8497 - accuracy: 0.7020 - val_loss: 1.0329 - val_accuracy: 0.6432\n",
            "Epoch 127/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8462 - accuracy: 0.7042 - val_loss: 1.0293 - val_accuracy: 0.6466\n",
            "Epoch 128/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8461 - accuracy: 0.7031 - val_loss: 1.0506 - val_accuracy: 0.6410\n",
            "Epoch 129/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8529 - accuracy: 0.7013 - val_loss: 1.0285 - val_accuracy: 0.6436\n",
            "Epoch 130/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8450 - accuracy: 0.7028 - val_loss: 1.0340 - val_accuracy: 0.6498\n",
            "Epoch 131/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8458 - accuracy: 0.7047 - val_loss: 1.0443 - val_accuracy: 0.6400\n",
            "Epoch 132/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8409 - accuracy: 0.7049 - val_loss: 1.0325 - val_accuracy: 0.6520\n",
            "Epoch 133/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8404 - accuracy: 0.7048 - val_loss: 1.0360 - val_accuracy: 0.6496\n",
            "Epoch 134/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8427 - accuracy: 0.7056 - val_loss: 1.0337 - val_accuracy: 0.6484\n",
            "Epoch 135/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8446 - accuracy: 0.7023 - val_loss: 1.0446 - val_accuracy: 0.6488\n",
            "Epoch 136/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8410 - accuracy: 0.7054 - val_loss: 1.0439 - val_accuracy: 0.6462\n",
            "Epoch 137/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8393 - accuracy: 0.7064 - val_loss: 1.0445 - val_accuracy: 0.6454\n",
            "Epoch 138/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8387 - accuracy: 0.7058 - val_loss: 1.0455 - val_accuracy: 0.6482\n",
            "Epoch 139/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8348 - accuracy: 0.7061 - val_loss: 1.0381 - val_accuracy: 0.6498\n",
            "Epoch 140/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8366 - accuracy: 0.7078 - val_loss: 1.0287 - val_accuracy: 0.6494\n",
            "Epoch 141/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8394 - accuracy: 0.7064 - val_loss: 1.0353 - val_accuracy: 0.6492\n",
            "Epoch 142/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8375 - accuracy: 0.7072 - val_loss: 1.0479 - val_accuracy: 0.6392\n",
            "Epoch 143/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8370 - accuracy: 0.7065 - val_loss: 1.0356 - val_accuracy: 0.6484\n",
            "Epoch 144/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8402 - accuracy: 0.7062 - val_loss: 1.0524 - val_accuracy: 0.6460\n",
            "Epoch 145/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8391 - accuracy: 0.7060 - val_loss: 1.0293 - val_accuracy: 0.6460\n",
            "Epoch 146/150\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8369 - accuracy: 0.7067 - val_loss: 1.0309 - val_accuracy: 0.6504\n",
            "Epoch 147/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8345 - accuracy: 0.7068 - val_loss: 1.0371 - val_accuracy: 0.6380\n",
            "Epoch 148/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8341 - accuracy: 0.7065 - val_loss: 1.0233 - val_accuracy: 0.6494\n",
            "Epoch 149/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8334 - accuracy: 0.7076 - val_loss: 1.0335 - val_accuracy: 0.6444\n",
            "Epoch 150/150\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.8321 - accuracy: 0.7090 - val_loss: 1.0430 - val_accuracy: 0.6498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aug_x_train1 = np.minimum(1.1*X_train_n2, 1)\n",
        "aug_x_train1 = normalize_tensor(aug_x_train1)\n",
        "aug_x_train2 = 0.9*X_train_n2\n",
        "aug_x_train2 = normalize_tensor(aug_x_train2)\n",
        "aug_x_train3 = tf.image.flip_left_right(X_train_n2)\n",
        "aug_x_train3 = normalize_tensor(aug_x_train3)\n",
        "aug_x_train4 = X_train_n2\n",
        "aug_x_train4 = normalize_tensor(aug_x_train4)"
      ],
      "metadata": {
        "id": "KtMysyxMYWNO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_aug = tf.concat([aug_x_train1,aug_x_train2,aug_x_train3,aug_x_train4],0)"
      ],
      "metadata": {
        "id": "6DDpadcBYWRh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_aug.shape"
      ],
      "metadata": {
        "id": "WTu2bJcayWta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b8fbfd2-aa35-4d87-fb53-5da51b782d2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([180000, 32, 32, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_aug = tf.concat([Y_train,Y_train,Y_train,Y_train],0)"
      ],
      "metadata": {
        "id": "1TE5CVn0YWWJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_n1 = X_train_aug\n",
        "X_val_n1 = normalize_tensor(X_val)"
      ],
      "metadata": {
        "id": "VKcdUHV5YWar"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.Sequential()\n",
        "model1.add(Conv2D(10, (5, 5), strides=(1,1), activation='relu', input_shape=(32, 32, 3),kernel_initializer=he_initializer))\n",
        "model1.add(MaxPooling2D((2, 2),strides=(2,2)))\n",
        "model1.add(Conv2D(10, (5, 5), activation='relu',kernel_initializer=he_initializer))\n",
        "model1.add(MaxPooling2D((2, 2),strides=2))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(units=20,activation='relu',kernel_initializer=he_initializer))\n",
        "model1.add(Dense(units=10,activation='softmax',kernel_initializer=he_initializer))"
      ],
      "metadata": {
        "id": "IC29qzSzYWfR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model1.compile(optimizer=adam,loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yTixx6PKYWj2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = model1.fit(X_train_n1, Y_train_aug, validation_data=(X_val_n1, Y_val), batch_size=512, epochs=150)"
      ],
      "metadata": {
        "id": "urGe6K0sYWoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6047a326-6e64-4432-c7dc-06b7b535255c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "352/352 [==============================] - 14s 14ms/step - loss: 1.7972 - accuracy: 0.3437 - val_loss: 1.4565 - val_accuracy: 0.4766\n",
            "Epoch 2/150\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 1.3697 - accuracy: 0.5096 - val_loss: 1.3170 - val_accuracy: 0.5250\n",
            "Epoch 3/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 1.2667 - accuracy: 0.5506 - val_loss: 1.2556 - val_accuracy: 0.5476\n",
            "Epoch 4/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2061 - accuracy: 0.5736 - val_loss: 1.2058 - val_accuracy: 0.5756\n",
            "Epoch 5/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1581 - accuracy: 0.5915 - val_loss: 1.1630 - val_accuracy: 0.5908\n",
            "Epoch 6/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1190 - accuracy: 0.6061 - val_loss: 1.1409 - val_accuracy: 0.5994\n",
            "Epoch 7/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.0896 - accuracy: 0.6171 - val_loss: 1.1292 - val_accuracy: 0.5960\n",
            "Epoch 8/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.0627 - accuracy: 0.6277 - val_loss: 1.0907 - val_accuracy: 0.6168\n",
            "Epoch 9/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.0431 - accuracy: 0.6340 - val_loss: 1.0673 - val_accuracy: 0.6200\n",
            "Epoch 10/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 1.0293 - accuracy: 0.6387 - val_loss: 1.0476 - val_accuracy: 0.6332\n",
            "Epoch 11/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 1.0142 - accuracy: 0.6439 - val_loss: 1.0411 - val_accuracy: 0.6342\n",
            "Epoch 12/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.9994 - accuracy: 0.6492 - val_loss: 1.0261 - val_accuracy: 0.6378\n",
            "Epoch 13/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.9897 - accuracy: 0.6535 - val_loss: 1.0503 - val_accuracy: 0.6316\n",
            "Epoch 14/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.9808 - accuracy: 0.6569 - val_loss: 1.0203 - val_accuracy: 0.6426\n",
            "Epoch 15/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.9722 - accuracy: 0.6595 - val_loss: 1.0147 - val_accuracy: 0.6460\n",
            "Epoch 16/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.9640 - accuracy: 0.6629 - val_loss: 1.0108 - val_accuracy: 0.6468\n",
            "Epoch 17/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.9544 - accuracy: 0.6669 - val_loss: 1.0134 - val_accuracy: 0.6470\n",
            "Epoch 18/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.9495 - accuracy: 0.6690 - val_loss: 0.9926 - val_accuracy: 0.6456\n",
            "Epoch 19/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.9433 - accuracy: 0.6707 - val_loss: 0.9939 - val_accuracy: 0.6516\n",
            "Epoch 20/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.9365 - accuracy: 0.6731 - val_loss: 0.9906 - val_accuracy: 0.6508\n",
            "Epoch 21/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.9325 - accuracy: 0.6744 - val_loss: 0.9844 - val_accuracy: 0.6526\n",
            "Epoch 22/150\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.9255 - accuracy: 0.6763 - val_loss: 1.0006 - val_accuracy: 0.6500\n",
            "Epoch 23/150\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.9224 - accuracy: 0.6778 - val_loss: 0.9891 - val_accuracy: 0.6536\n",
            "Epoch 24/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.9176 - accuracy: 0.6796 - val_loss: 0.9775 - val_accuracy: 0.6552\n",
            "Epoch 25/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.9146 - accuracy: 0.6798 - val_loss: 0.9763 - val_accuracy: 0.6580\n",
            "Epoch 26/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.9101 - accuracy: 0.6819 - val_loss: 0.9857 - val_accuracy: 0.6546\n",
            "Epoch 27/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.9076 - accuracy: 0.6828 - val_loss: 0.9753 - val_accuracy: 0.6552\n",
            "Epoch 28/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.9041 - accuracy: 0.6840 - val_loss: 0.9812 - val_accuracy: 0.6610\n",
            "Epoch 29/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.9004 - accuracy: 0.6856 - val_loss: 0.9707 - val_accuracy: 0.6634\n",
            "Epoch 30/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8957 - accuracy: 0.6875 - val_loss: 0.9807 - val_accuracy: 0.6578\n",
            "Epoch 31/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8927 - accuracy: 0.6878 - val_loss: 0.9773 - val_accuracy: 0.6606\n",
            "Epoch 32/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8888 - accuracy: 0.6894 - val_loss: 0.9720 - val_accuracy: 0.6646\n",
            "Epoch 33/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8854 - accuracy: 0.6904 - val_loss: 0.9698 - val_accuracy: 0.6632\n",
            "Epoch 34/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8848 - accuracy: 0.6903 - val_loss: 0.9687 - val_accuracy: 0.6654\n",
            "Epoch 35/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8820 - accuracy: 0.6919 - val_loss: 0.9623 - val_accuracy: 0.6626\n",
            "Epoch 36/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8790 - accuracy: 0.6925 - val_loss: 0.9705 - val_accuracy: 0.6656\n",
            "Epoch 37/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8796 - accuracy: 0.6923 - val_loss: 0.9739 - val_accuracy: 0.6584\n",
            "Epoch 38/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8755 - accuracy: 0.6940 - val_loss: 0.9697 - val_accuracy: 0.6620\n",
            "Epoch 39/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8723 - accuracy: 0.6947 - val_loss: 0.9778 - val_accuracy: 0.6624\n",
            "Epoch 40/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8706 - accuracy: 0.6953 - val_loss: 0.9646 - val_accuracy: 0.6674\n",
            "Epoch 41/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8693 - accuracy: 0.6960 - val_loss: 0.9702 - val_accuracy: 0.6654\n",
            "Epoch 42/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8682 - accuracy: 0.6966 - val_loss: 0.9669 - val_accuracy: 0.6654\n",
            "Epoch 43/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8631 - accuracy: 0.6971 - val_loss: 0.9679 - val_accuracy: 0.6654\n",
            "Epoch 44/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8623 - accuracy: 0.6984 - val_loss: 0.9656 - val_accuracy: 0.6636\n",
            "Epoch 45/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8625 - accuracy: 0.6976 - val_loss: 0.9633 - val_accuracy: 0.6646\n",
            "Epoch 46/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8597 - accuracy: 0.6982 - val_loss: 0.9608 - val_accuracy: 0.6654\n",
            "Epoch 47/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.8579 - accuracy: 0.6994 - val_loss: 0.9712 - val_accuracy: 0.6648\n",
            "Epoch 48/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8565 - accuracy: 0.6997 - val_loss: 0.9597 - val_accuracy: 0.6686\n",
            "Epoch 49/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8544 - accuracy: 0.7013 - val_loss: 0.9598 - val_accuracy: 0.6716\n",
            "Epoch 50/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8511 - accuracy: 0.7023 - val_loss: 0.9479 - val_accuracy: 0.6688\n",
            "Epoch 51/150\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.8500 - accuracy: 0.7019 - val_loss: 0.9562 - val_accuracy: 0.6720\n",
            "Epoch 52/150\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.8484 - accuracy: 0.7027 - val_loss: 0.9528 - val_accuracy: 0.6744\n",
            "Epoch 53/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8488 - accuracy: 0.7036 - val_loss: 0.9689 - val_accuracy: 0.6682\n",
            "Epoch 54/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8452 - accuracy: 0.7046 - val_loss: 0.9737 - val_accuracy: 0.6634\n",
            "Epoch 55/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8441 - accuracy: 0.7039 - val_loss: 0.9569 - val_accuracy: 0.6716\n",
            "Epoch 56/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.8416 - accuracy: 0.7048 - val_loss: 0.9507 - val_accuracy: 0.6684\n",
            "Epoch 57/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8415 - accuracy: 0.7052 - val_loss: 0.9560 - val_accuracy: 0.6726\n",
            "Epoch 58/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8402 - accuracy: 0.7063 - val_loss: 0.9563 - val_accuracy: 0.6716\n",
            "Epoch 59/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.8401 - accuracy: 0.7062 - val_loss: 0.9649 - val_accuracy: 0.6688\n",
            "Epoch 60/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.8377 - accuracy: 0.7072 - val_loss: 0.9629 - val_accuracy: 0.6658\n",
            "Epoch 61/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8357 - accuracy: 0.7069 - val_loss: 0.9640 - val_accuracy: 0.6684\n",
            "Epoch 62/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8358 - accuracy: 0.7073 - val_loss: 0.9552 - val_accuracy: 0.6674\n",
            "Epoch 63/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8366 - accuracy: 0.7062 - val_loss: 0.9564 - val_accuracy: 0.6646\n",
            "Epoch 64/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8333 - accuracy: 0.7083 - val_loss: 0.9582 - val_accuracy: 0.6650\n",
            "Epoch 65/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8333 - accuracy: 0.7079 - val_loss: 0.9627 - val_accuracy: 0.6684\n",
            "Epoch 66/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8294 - accuracy: 0.7087 - val_loss: 0.9571 - val_accuracy: 0.6700\n",
            "Epoch 67/150\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.8297 - accuracy: 0.7094 - val_loss: 0.9538 - val_accuracy: 0.6722\n",
            "Epoch 68/150\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.8298 - accuracy: 0.7090 - val_loss: 0.9517 - val_accuracy: 0.6666\n",
            "Epoch 69/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8286 - accuracy: 0.7094 - val_loss: 0.9645 - val_accuracy: 0.6726\n",
            "Epoch 70/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8277 - accuracy: 0.7096 - val_loss: 0.9477 - val_accuracy: 0.6734\n",
            "Epoch 71/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8267 - accuracy: 0.7105 - val_loss: 0.9521 - val_accuracy: 0.6720\n",
            "Epoch 72/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8252 - accuracy: 0.7111 - val_loss: 0.9471 - val_accuracy: 0.6740\n",
            "Epoch 73/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8250 - accuracy: 0.7099 - val_loss: 0.9560 - val_accuracy: 0.6706\n",
            "Epoch 74/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8225 - accuracy: 0.7122 - val_loss: 0.9467 - val_accuracy: 0.6742\n",
            "Epoch 75/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8231 - accuracy: 0.7102 - val_loss: 0.9494 - val_accuracy: 0.6766\n",
            "Epoch 76/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8208 - accuracy: 0.7121 - val_loss: 0.9570 - val_accuracy: 0.6712\n",
            "Epoch 77/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8215 - accuracy: 0.7118 - val_loss: 0.9611 - val_accuracy: 0.6686\n",
            "Epoch 78/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8182 - accuracy: 0.7126 - val_loss: 0.9637 - val_accuracy: 0.6680\n",
            "Epoch 79/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8184 - accuracy: 0.7125 - val_loss: 0.9625 - val_accuracy: 0.6710\n",
            "Epoch 80/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8186 - accuracy: 0.7121 - val_loss: 0.9551 - val_accuracy: 0.6732\n",
            "Epoch 81/150\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.8168 - accuracy: 0.7133 - val_loss: 0.9472 - val_accuracy: 0.6764\n",
            "Epoch 82/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8160 - accuracy: 0.7129 - val_loss: 0.9707 - val_accuracy: 0.6700\n",
            "Epoch 83/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8155 - accuracy: 0.7134 - val_loss: 0.9597 - val_accuracy: 0.6694\n",
            "Epoch 84/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8173 - accuracy: 0.7132 - val_loss: 0.9526 - val_accuracy: 0.6692\n",
            "Epoch 85/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.8154 - accuracy: 0.7136 - val_loss: 0.9548 - val_accuracy: 0.6718\n",
            "Epoch 86/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.8150 - accuracy: 0.7135 - val_loss: 0.9602 - val_accuracy: 0.6676\n",
            "Epoch 87/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.8134 - accuracy: 0.7145 - val_loss: 0.9681 - val_accuracy: 0.6678\n",
            "Epoch 88/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.8142 - accuracy: 0.7143 - val_loss: 0.9548 - val_accuracy: 0.6746\n",
            "Epoch 89/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.8115 - accuracy: 0.7156 - val_loss: 0.9489 - val_accuracy: 0.6748\n",
            "Epoch 90/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.8112 - accuracy: 0.7157 - val_loss: 0.9608 - val_accuracy: 0.6756\n",
            "Epoch 91/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.8107 - accuracy: 0.7146 - val_loss: 0.9579 - val_accuracy: 0.6734\n",
            "Epoch 92/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8093 - accuracy: 0.7164 - val_loss: 0.9489 - val_accuracy: 0.6738\n",
            "Epoch 93/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8085 - accuracy: 0.7165 - val_loss: 0.9479 - val_accuracy: 0.6770\n",
            "Epoch 94/150\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.8077 - accuracy: 0.7165 - val_loss: 0.9603 - val_accuracy: 0.6720\n",
            "Epoch 95/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8076 - accuracy: 0.7160 - val_loss: 0.9591 - val_accuracy: 0.6712\n",
            "Epoch 96/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8049 - accuracy: 0.7171 - val_loss: 0.9521 - val_accuracy: 0.6754\n",
            "Epoch 97/150\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.8052 - accuracy: 0.7174 - val_loss: 0.9570 - val_accuracy: 0.6744\n",
            "Epoch 98/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8050 - accuracy: 0.7171 - val_loss: 0.9611 - val_accuracy: 0.6718\n",
            "Epoch 99/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8019 - accuracy: 0.7188 - val_loss: 0.9456 - val_accuracy: 0.6756\n",
            "Epoch 100/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8020 - accuracy: 0.7185 - val_loss: 0.9642 - val_accuracy: 0.6692\n",
            "Epoch 101/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8009 - accuracy: 0.7193 - val_loss: 0.9525 - val_accuracy: 0.6770\n",
            "Epoch 102/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8010 - accuracy: 0.7192 - val_loss: 0.9609 - val_accuracy: 0.6740\n",
            "Epoch 103/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8014 - accuracy: 0.7182 - val_loss: 0.9583 - val_accuracy: 0.6700\n",
            "Epoch 104/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7984 - accuracy: 0.7198 - val_loss: 0.9577 - val_accuracy: 0.6740\n",
            "Epoch 105/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7990 - accuracy: 0.7202 - val_loss: 0.9611 - val_accuracy: 0.6732\n",
            "Epoch 106/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7985 - accuracy: 0.7195 - val_loss: 0.9466 - val_accuracy: 0.6754\n",
            "Epoch 107/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7993 - accuracy: 0.7197 - val_loss: 0.9467 - val_accuracy: 0.6772\n",
            "Epoch 108/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7983 - accuracy: 0.7204 - val_loss: 0.9534 - val_accuracy: 0.6786\n",
            "Epoch 109/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7953 - accuracy: 0.7203 - val_loss: 0.9521 - val_accuracy: 0.6746\n",
            "Epoch 110/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7964 - accuracy: 0.7203 - val_loss: 0.9480 - val_accuracy: 0.6814\n",
            "Epoch 111/150\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.7949 - accuracy: 0.7208 - val_loss: 0.9450 - val_accuracy: 0.6794\n",
            "Epoch 112/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7962 - accuracy: 0.7206 - val_loss: 0.9481 - val_accuracy: 0.6746\n",
            "Epoch 113/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7929 - accuracy: 0.7223 - val_loss: 0.9587 - val_accuracy: 0.6772\n",
            "Epoch 114/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7940 - accuracy: 0.7215 - val_loss: 0.9538 - val_accuracy: 0.6780\n",
            "Epoch 115/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.7938 - accuracy: 0.7216 - val_loss: 0.9513 - val_accuracy: 0.6774\n",
            "Epoch 116/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7910 - accuracy: 0.7225 - val_loss: 0.9465 - val_accuracy: 0.6810\n",
            "Epoch 117/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7927 - accuracy: 0.7217 - val_loss: 0.9519 - val_accuracy: 0.6748\n",
            "Epoch 118/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.7918 - accuracy: 0.7223 - val_loss: 0.9646 - val_accuracy: 0.6710\n",
            "Epoch 119/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.7924 - accuracy: 0.7221 - val_loss: 0.9485 - val_accuracy: 0.6804\n",
            "Epoch 120/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.7899 - accuracy: 0.7227 - val_loss: 0.9580 - val_accuracy: 0.6764\n",
            "Epoch 121/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7911 - accuracy: 0.7225 - val_loss: 0.9556 - val_accuracy: 0.6738\n",
            "Epoch 122/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7903 - accuracy: 0.7228 - val_loss: 0.9622 - val_accuracy: 0.6704\n",
            "Epoch 123/150\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7888 - accuracy: 0.7239 - val_loss: 0.9604 - val_accuracy: 0.6734\n",
            "Epoch 124/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.7908 - accuracy: 0.7220 - val_loss: 0.9700 - val_accuracy: 0.6688\n",
            "Epoch 125/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.7898 - accuracy: 0.7229 - val_loss: 0.9534 - val_accuracy: 0.6764\n",
            "Epoch 126/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.7861 - accuracy: 0.7246 - val_loss: 0.9577 - val_accuracy: 0.6716\n",
            "Epoch 127/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.7850 - accuracy: 0.7250 - val_loss: 0.9525 - val_accuracy: 0.6758\n",
            "Epoch 128/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.7854 - accuracy: 0.7245 - val_loss: 0.9563 - val_accuracy: 0.6724\n",
            "Epoch 129/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7856 - accuracy: 0.7249 - val_loss: 0.9496 - val_accuracy: 0.6780\n",
            "Epoch 130/150\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.7863 - accuracy: 0.7239 - val_loss: 0.9438 - val_accuracy: 0.6810\n",
            "Epoch 131/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7861 - accuracy: 0.7245 - val_loss: 0.9477 - val_accuracy: 0.6810\n",
            "Epoch 132/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7843 - accuracy: 0.7247 - val_loss: 0.9629 - val_accuracy: 0.6730\n",
            "Epoch 133/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7866 - accuracy: 0.7232 - val_loss: 0.9489 - val_accuracy: 0.6816\n",
            "Epoch 134/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7852 - accuracy: 0.7243 - val_loss: 0.9529 - val_accuracy: 0.6778\n",
            "Epoch 135/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7848 - accuracy: 0.7246 - val_loss: 0.9568 - val_accuracy: 0.6738\n",
            "Epoch 136/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7856 - accuracy: 0.7239 - val_loss: 0.9578 - val_accuracy: 0.6720\n",
            "Epoch 137/150\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.7818 - accuracy: 0.7255 - val_loss: 0.9449 - val_accuracy: 0.6760\n",
            "Epoch 138/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7814 - accuracy: 0.7255 - val_loss: 0.9548 - val_accuracy: 0.6774\n",
            "Epoch 139/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7809 - accuracy: 0.7248 - val_loss: 0.9594 - val_accuracy: 0.6756\n",
            "Epoch 140/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7840 - accuracy: 0.7239 - val_loss: 0.9586 - val_accuracy: 0.6766\n",
            "Epoch 141/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7820 - accuracy: 0.7246 - val_loss: 0.9547 - val_accuracy: 0.6714\n",
            "Epoch 142/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7791 - accuracy: 0.7264 - val_loss: 0.9745 - val_accuracy: 0.6678\n",
            "Epoch 143/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7810 - accuracy: 0.7255 - val_loss: 0.9776 - val_accuracy: 0.6686\n",
            "Epoch 144/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7811 - accuracy: 0.7259 - val_loss: 0.9547 - val_accuracy: 0.6780\n",
            "Epoch 145/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7804 - accuracy: 0.7260 - val_loss: 0.9511 - val_accuracy: 0.6808\n",
            "Epoch 146/150\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.7788 - accuracy: 0.7272 - val_loss: 0.9740 - val_accuracy: 0.6684\n",
            "Epoch 147/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7793 - accuracy: 0.7265 - val_loss: 0.9574 - val_accuracy: 0.6758\n",
            "Epoch 148/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7783 - accuracy: 0.7270 - val_loss: 0.9584 - val_accuracy: 0.6804\n",
            "Epoch 149/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7790 - accuracy: 0.7265 - val_loss: 0.9607 - val_accuracy: 0.6726\n",
            "Epoch 150/150\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.7785 - accuracy: 0.7268 - val_loss: 0.9547 - val_accuracy: 0.6726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc1 = r.history['val_accuracy']\n",
        "val_acc2 = r1.history['val_accuracy']"
      ],
      "metadata": {
        "id": "tiyaXw0qYWsj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, 151)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, val_acc1, 'bo', label='Validation accuracy for Normal Data')\n",
        "plt.plot(epochs, val_acc2, 'b', label='Validation accuracy for Augmented Data')\n",
        "plt.title('Validation accuracy for both Normal and Augmented Dataset')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2Ei36wU-YWxE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "21824fb5-6cf0-4c69-c3e7-7c1323b54da5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2: Self-Supervised Learning via Pretext Tasks "
      ],
      "metadata": {
        "id": "Lo-JSUqhyixs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = tf.keras.datasets.cifar10"
      ],
      "metadata": {
        "id": "68LRZcGUYW1i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "19rVPsDqYW6G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bfd0ba8-a69f-46b7-e484-1e90073440ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labelled_X_train,unlabelled_X_train = x_train[49500:50000],x_train[0:49500]"
      ],
      "metadata": {
        "id": "GyVw9cRyYW-Z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labelled_X_train.shape)\n",
        "print(unlabelled_X_train.shape)"
      ],
      "metadata": {
        "id": "Mk7FRyMsYXDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63a9636-ed28-43d7-e428-cdcfc743a91e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 32, 32, 3)\n",
            "(49500, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[0:49500].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbhZisPsALhS",
        "outputId": "7634de04-4bca-4f92-9b4f-43bc98a54808"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train0 = tf.zeros(shape = y_train[0:49500].shape,dtype=tf.int32)"
      ],
      "metadata": {
        "id": "BzToqawe_3Jg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_upside_down = tf.image.flip_up_down(unlabelled_X_train)\n",
        "Y_train1 = tf.ones(shape=y_train[0:49500].shape,dtype=tf.int32)\n",
        "X_train_rotated_ccwise = tf.image.rot90(unlabelled_X_train)\n",
        "Y_train2 = 2*tf.ones(shape=y_train[0:49500].shape,dtype=tf.int32)"
      ],
      "metadata": {
        "id": "CIAv03T4YXHH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_aug = tf.concat([unlabelled_X_train,X_train_upside_down,X_train_rotated_ccwise],0)\n",
        "Y_train_aug = tf.concat([Y_train0,Y_train1,Y_train2],0)"
      ],
      "metadata": {
        "id": "wzBXU_PZYXLh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_aug.shape"
      ],
      "metadata": {
        "id": "AiyzDUqEYXPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf3529cb-43ea-4152-95b5-0adddd303f48"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([148500, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(Conv2D(10, (5, 5), strides=(1,1), activation='relu', input_shape=(32, 32, 3),kernel_initializer=he_initializer))\n",
        "    model.add(MaxPooling2D((2, 2),strides=(2,2)))\n",
        "    model.add(Conv2D(10, (5, 5), activation='relu',kernel_initializer=he_initializer))\n",
        "    model.add(MaxPooling2D((2, 2),strides=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=20,activation='relu',kernel_initializer=he_initializer))\n",
        "    model.add(Dense(units=10,activation='softmax',kernel_initializer=he_initializer))\n",
        "    return model"
      ],
      "metadata": {
        "id": "cxqBrVFCYXT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "metadata": {
        "id": "1wVwUzpzYXX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)"
      ],
      "metadata": {
        "id": "gpY5sX1LYXcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 save_freq=50*batch_size,\n",
        "                                                 verbose=1)"
      ],
      "metadata": {
        "id": "MbUwR2h0YXgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_aug, \n",
        "          Y_train_aug,  \n",
        "          epochs=100,\n",
        "          batch_size=batch_size,\n",
        "          callbacks=[cp_callback])"
      ],
      "metadata": {
        "id": "vEiJPsofy20P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(checkpoint_dir)"
      ],
      "metadata": {
        "id": "RNb7pr19y266"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "metadata": {
        "id": "sR0MTAWay3BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Load the previously saved weights\n",
        "model.load_weights(latest)\n",
        "\n",
        "# Re-evaluate the model\n",
        "# loss, acc = model.evaluate(test_images, test_labels, verbose=2)"
      ],
      "metadata": {
        "id": "tloxqvUfy3G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PqpxuzY6y3My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KPeBlEray3Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_0YrfgM3y3Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6T6AAeCby3bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dm6Z7rIgy3hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3: Speech Denoising Using RNN"
      ],
      "metadata": {
        "id": "rxt4OqKey4hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip '/content/drive/MyDrive/DLS_DATA/homework3.zip' -d '/content/drive/MyDrive/DLS_DATA/timit-hw3'"
      ],
      "metadata": {
        "id": "fe8b-HYUFT3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/DLS_DATA/timit-hw3/timit-homework/tr'\n",
        "\n",
        "X = []\n",
        "S = []\n",
        "N = []\n",
        "\n",
        "for f in os.listdir(path):\n",
        "    if(os.path.isfile(os.path.join(path,f))):\n",
        "        if(f[:3]=='trn'):\n",
        "          s, sr = librosa.load(os.path.join(path,f),sr=None)\n",
        "          trn_stft=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "          N.append(abs(trn_stft))\n",
        "        elif(f[:3]=='trs'):\n",
        "          s, sr = librosa.load(os.path.join(path,f),sr=None)\n",
        "          trs_stft=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "          S.append(abs(trs_stft))\n",
        "        else:\n",
        "          s, sr = librosa.load(os.path.join(path,f),sr=None)\n",
        "          trx_stft=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "          X.append(abs(trx_stft))"
      ],
      "metadata": {
        "id": "8_-XlVP2FTqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(N[-1].shape)\n",
        "print(S[-1].shape)\n",
        "print(X[-1].shape)"
      ],
      "metadata": {
        "id": "UTtHHE4xFRm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = X[0].shape[1]\n",
        "for k in range(1,len(X)):\n",
        "    if(X[k].shape[1]>max_len):\n",
        "        max_len = X[k].shape[1]\n",
        "print(max_len)"
      ],
      "metadata": {
        "id": "_D3FWTq7Serl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M_arr = []\n",
        "for i in range(len(N)):\n",
        "    # print(\"Before:\",S[i].shape,N[i].shape)\n",
        "    if(S[i].shape[1]<N[i].shape[1]):\n",
        "        S[i] = np.pad(S[i],((0,0),(0,N[i].shape[1]-S[i].shape[1])),mode='constant')\n",
        "    elif(S[i].shape[1]>N[i].shape[1]):\n",
        "        N[i] = np.pad(N[i],((0,0),(0,S[i].shape[1]-N[i].shape[1])),mode='constant')\n",
        "    # print(\"After:\",S[i].shape,N[i].shape)\n",
        "    M = np.where((S[i]>N[i]),1,0)\n",
        "    M_arr.append(M)"
      ],
      "metadata": {
        "id": "1RFGLGOoFRdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X)):\n",
        "    X[i] = np.pad(X[i],((0,0),(0,max_len-X[i].shape[1])),mode='constant')\n",
        "    X[i] = X[i].T\n",
        "    M_arr[i] = np.pad(M_arr[i],((0,0),(0,max_len-M_arr[i].shape[1])),mode='constant')\n",
        "    M_arr[i] = M_arr[i].T"
      ],
      "metadata": {
        "id": "FZfEqvIZNnJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(M_arr[0].shape)\n",
        "print(M_arr[1].shape)\n",
        "print(M_arr[2].shape)\n",
        "print(M_arr[3].shape)"
      ],
      "metadata": {
        "id": "ZnPUDEcgFCgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.dstack(X)\n",
        "X = np.rollaxis(X,-1)\n",
        "M_arr = np.dstack(M_arr)\n",
        "M_arr = np.rollaxis(M_arr,-1)\n",
        "print(X.shape)\n",
        "print(M_arr.shape)"
      ],
      "metadata": {
        "id": "HFeL3bVfNcHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
        "M_arr = tf.convert_to_tensor(M_arr, dtype=tf.float32)\n",
        "print(X.shape)\n",
        "print(M_arr.shape)"
      ],
      "metadata": {
        "id": "Bn97jYsoLkQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.Input(shape=(max_len,513),batch_size=10))\n",
        "model.add(tf.keras.layers.GRU(513, return_sequences=True, input_shape =(max_len,513), dropout=0.3))\n",
        "model.add(tf.keras.layers.GRU(513, return_sequences=True, dropout=0.3))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units=1024,activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units=513,activation='relu'))\n",
        "model.compile(optimizer='adam',loss = 'mean_squared_error')"
      ],
      "metadata": {
        "id": "qJhf4v7OFCpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "aMfguG3GKwkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,M_arr,batch_size=10,epochs=100)"
      ],
      "metadata": {
        "id": "7Em4vMJBFCvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "edzc3tnyFC1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YPWs5deCFC6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9_OM_L7zFDC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KS0yNnFmFDHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tczbMRTQFDMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pLgkT4P6FDQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EA-3W0f-FG7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yiNmdelAFHAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wsn7ya0qFHEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eIC58pqjFHIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9UFKbulEFHL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L-qVH74xFHQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vm9fvMymFHTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W6zSsETtFHXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "99Ypd8YYFHb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5TyGLNpHFHfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sQH7GLAIFHjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YVFFjCfUFHnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "96J55uoiFHrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YhOfhcWlFHv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_BuKSPlWFH0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iey9YMSjFH39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xYn1dYH9FH8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "57nPZtRNFIAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AbxRX_l4FIDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s7YeRbddFIHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7E5CZlXVFILS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nm8FpT-4FIO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "njmZj_MIFITW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YqOjAGNiFIXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Ue61RgCFIbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "03RdePq_FIew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c95_wjMAFIig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wMiIkZbRFImH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}