{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLcquFLl/xmuc2KnAdMwDu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ram130849/Deep_Learning_Systems_Assignments/blob/main/TensorFlow/Tejas/DeepLearning_HW1_Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 3 Dropout"
      ],
      "metadata": {
        "id": "AK6HpregaNsw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZHkBXOXaKBd",
        "outputId": "6653bd92-da90-497b-e851-96f7fdffa6e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "#Path: TensorFlow/Tejas/\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils\n",
        "%matplotlib inline  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv1H9UoAa8u6",
        "outputId": "ab9b0806-83e9-49c9-e8e5-13db2f54d3c1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ61ymmJa-ix",
        "outputId": "9a3b326f-5128-4be2-b7d7-ce65e792b54d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "2.8154721180000024\n",
            "GPU (s):\n",
            "0.041225295000003825\n",
            "GPU speedup over CPU: 68x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ad hoc mnist instances\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# load (downloaded if needed) the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjD4-o7bbBMk",
        "outputId": "d1524f2e-16c2-4214-d1f3-ba2a1fb45b3a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets see the shapes of each Data sets\n",
        "print(\"TRAIN SET:\")\n",
        "print(\"Training Set X_train shape is : {}\".format(X_train.shape))\n",
        "print(\"Training Set y_train shape is : {}\".format(y_train.shape))\n",
        "print(\"____\"*25)\n",
        "print(\"TEST SET:\")\n",
        "print(\"Test Set X_test shape is : {}\".format(X_test.shape))\n",
        "print(\"Test Set y_test shape is : {}\".format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01tvVRsHbDm_",
        "outputId": "ad59c858-6ca6-4742-d8f4-c32accc443c6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN SET:\n",
            "Training Set X_train shape is : (60000, 28, 28)\n",
            "Training Set y_train shape is : (60000,)\n",
            "____________________________________________________________________________________________________\n",
            "TEST SET:\n",
            "Test Set X_test shape is : (10000, 28, 28)\n",
            "Test Set y_test shape is : (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One way of flattening input, chose this I faced many issues with input shapes while doing it inside the model\n",
        "X_train = X_train.reshape(X_train.shape[0], 784)\n",
        "X_test = X_test.reshape(X_test.shape[0], 784) \n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "metadata": {
        "id": "lZxB7jAjbFdE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "num_classes = 10\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "2SY5uf9_bJKO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model_no_drop(act_fxn,init):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1024, input_shape=(28*28,), activation=act_fxn, kernel_initializer=init),\n",
        "    tf.keras.layers.Dense(units=1024, activation=act_fxn),\n",
        "    tf.keras.layers.Dense(units=1024, activation=act_fxn),\n",
        "    tf.keras.layers.Dense(units=1024, activation=act_fxn),\n",
        "    tf.keras.layers.Dense(units=1024, activation=act_fxn),\n",
        "    tf.keras.layers.Dense(units=10, activation=\"softmax\")\n",
        "  ])\n",
        "  return model "
      ],
      "metadata": {
        "id": "NQ5h0gxLbL7T"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01)\n",
        "xavier_ini_normal = tf.keras.initializers.GlorotNormal()\n",
        "xavier_initializer = tf.keras.initializers.GlorotUniform()\n",
        "he_initializer = tf.keras.initializers.HeNormal()"
      ],
      "metadata": {
        "id": "M_JuQb6IbW0a"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import  Dense, Dropout, Activation, Flatten"
      ],
      "metadata": {
        "id": "oXbUhXEQesY2"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = define_model_no_drop(act_fxn= 'sigmoid',init =xavier_ini_normal )\n",
        "\n",
        "\n",
        "model3 = define_model_no_drop(act_fxn= 'relu',init = he_initializer)"
      ],
      "metadata": {
        "id": "pvi4utVtbxSL"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28*28,)),\n",
        "  tf.keras.layers.Dense(1024,activation='sigmoid',kernel_initializer=xavier_initializer),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(1024,activation='sigmoid',kernel_initializer=xavier_initializer),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(1024,activation='sigmoid',kernel_initializer=xavier_initializer),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(1024,activation='sigmoid',kernel_initializer=xavier_initializer),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(10,kernel_initializer=xavier_initializer)\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "vzc5S1MGd1Qf"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28*28,)),\n",
        "  tf.keras.layers.Dense(1024,activation='relu',kernel_initializer=he_initializer),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(1024,activation='relu',kernel_initializer=he_initializer),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(1024,activation='relu',kernel_initializer=he_initializer),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(1024,activation='relu',kernel_initializer=he_initializer),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(10,kernel_initializer=he_initializer)\n",
        "])"
      ],
      "metadata": {
        "id": "LFFc9Wl8eGL_"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = tf.keras.optimizers.Adam()"
      ],
      "metadata": {
        "id": "rpvBZsvPgotV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model1.compile(optimizer=adam, loss= 'categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "history1 = model1.fit(X_train,y_train,epochs=200,batch_size=128,verbose=True,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUid-RIpgE47",
        "outputId": "1b965201-398a-4d3c-e0a0-aa0d3b2f1b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 2.3752 - accuracy: 0.1023 - val_loss: 2.3113 - val_accuracy: 0.1010\n",
            "Epoch 2/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3063 - accuracy: 0.1040 - val_loss: 2.3055 - val_accuracy: 0.1135\n",
            "Epoch 3/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 2.3045 - accuracy: 0.1059 - val_loss: 2.3032 - val_accuracy: 0.1135\n",
            "Epoch 4/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 2.3033 - accuracy: 0.1078 - val_loss: 2.3032 - val_accuracy: 0.1010\n",
            "Epoch 5/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3028 - accuracy: 0.1085 - val_loss: 2.3036 - val_accuracy: 0.1028\n",
            "Epoch 6/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3025 - accuracy: 0.1098 - val_loss: 2.3027 - val_accuracy: 0.1135\n",
            "Epoch 7/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3024 - accuracy: 0.1089 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
            "Epoch 8/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.1987 - accuracy: 0.1448 - val_loss: 1.7113 - val_accuracy: 0.2860\n",
            "Epoch 9/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.2844 - accuracy: 0.4883 - val_loss: 0.6937 - val_accuracy: 0.7533\n",
            "Epoch 10/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3881 - accuracy: 0.9078 - val_loss: 0.2796 - val_accuracy: 0.9440\n",
            "Epoch 11/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1926 - accuracy: 0.9579 - val_loss: 0.1965 - val_accuracy: 0.9559\n",
            "Epoch 12/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1299 - accuracy: 0.9692 - val_loss: 0.1698 - val_accuracy: 0.9637\n",
            "Epoch 13/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0963 - accuracy: 0.9761 - val_loss: 0.1508 - val_accuracy: 0.9676\n",
            "Epoch 14/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0771 - accuracy: 0.9807 - val_loss: 0.1469 - val_accuracy: 0.9686\n",
            "Epoch 15/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0632 - accuracy: 0.9830 - val_loss: 0.1304 - val_accuracy: 0.9731\n",
            "Epoch 16/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0505 - accuracy: 0.9869 - val_loss: 0.1287 - val_accuracy: 0.9739\n",
            "Epoch 17/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0403 - accuracy: 0.9898 - val_loss: 0.1143 - val_accuracy: 0.9766\n",
            "Epoch 18/200\n",
            "180/469 [==========>...................] - ETA: 1s - loss: 0.0361 - accuracy: 0.9902"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model2.compile(optimizer=adam, loss= 'categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "history2 = model2.fit(X_train,y_train,epochs=200,batch_size=128,verbose=True,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1GzNdNBgTXu",
        "outputId": "d358d220-d251-4522-c688-dfa9c63a6512"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "469/469 [==============================] - 4s 6ms/step - loss: 6.6910 - accuracy: 0.0979 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 2/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 8.3129 - accuracy: 0.0984 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 3/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 8.3086 - accuracy: 0.0978 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 4/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3118 - accuracy: 0.0970 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 5/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3083 - accuracy: 0.0991 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 6/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3110 - accuracy: 0.0972 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 7/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3043 - accuracy: 0.0993 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 8/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3054 - accuracy: 0.0984 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 9/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2729 - accuracy: 0.0987 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 10/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3092 - accuracy: 0.0974 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 11/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2850 - accuracy: 0.0977 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 12/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2675 - accuracy: 0.0978 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 13/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2535 - accuracy: 0.0995 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 14/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3231 - accuracy: 0.0985 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 15/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2412 - accuracy: 0.0968 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 16/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2595 - accuracy: 0.0986 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 17/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2906 - accuracy: 0.0979 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 18/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2745 - accuracy: 0.0977 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 19/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2809 - accuracy: 0.0964 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 20/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2683 - accuracy: 0.0972 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 21/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2729 - accuracy: 0.0986 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 22/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2377 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 23/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2423 - accuracy: 0.0989 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 24/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2882 - accuracy: 0.0974 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 25/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2726 - accuracy: 0.0979 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 26/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2799 - accuracy: 0.0987 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 27/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2565 - accuracy: 0.0964 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 28/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2640 - accuracy: 0.0956 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 29/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2517 - accuracy: 0.0981 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 30/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2541 - accuracy: 0.0962 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 31/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2498 - accuracy: 0.0964 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 32/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2718 - accuracy: 0.0999 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 33/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2801 - accuracy: 0.0976 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 34/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 8.2758 - accuracy: 0.0970 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 35/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2460 - accuracy: 0.0975 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 36/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2745 - accuracy: 0.0977 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 37/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2780 - accuracy: 0.0982 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 38/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2621 - accuracy: 0.0959 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 39/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2326 - accuracy: 0.0978 - val_loss: 8.3605 - val_accuracy: 0.0958\n",
            "Epoch 40/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2167 - accuracy: 0.0970 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 41/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2968 - accuracy: 0.0950 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 42/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2562 - accuracy: 0.0964 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 43/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2342 - accuracy: 0.0963 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 44/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2662 - accuracy: 0.0960 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 45/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2527 - accuracy: 0.0957 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 46/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2576 - accuracy: 0.0984 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 47/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2855 - accuracy: 0.0963 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 48/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2632 - accuracy: 0.0969 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 49/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2761 - accuracy: 0.0965 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 50/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2519 - accuracy: 0.0953 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 51/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2372 - accuracy: 0.0960 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 52/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2506 - accuracy: 0.0989 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 53/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2777 - accuracy: 0.0986 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 54/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2374 - accuracy: 0.0959 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 55/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2511 - accuracy: 0.0966 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 56/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2928 - accuracy: 0.0962 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 57/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2498 - accuracy: 0.0956 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 58/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2605 - accuracy: 0.0964 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 59/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2866 - accuracy: 0.0983 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 60/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2570 - accuracy: 0.0963 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 61/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2831 - accuracy: 0.0977 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 62/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2514 - accuracy: 0.0954 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 63/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2605 - accuracy: 0.0951 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 64/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2495 - accuracy: 0.0981 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 65/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2890 - accuracy: 0.0964 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 66/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2398 - accuracy: 0.0974 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 67/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2710 - accuracy: 0.0953 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 68/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3024 - accuracy: 0.0970 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 69/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2705 - accuracy: 0.0957 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 70/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2629 - accuracy: 0.0956 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 71/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3081 - accuracy: 0.0967 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 72/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2541 - accuracy: 0.0976 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 73/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3126 - accuracy: 0.0969 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 74/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2667 - accuracy: 0.0982 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 75/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2995 - accuracy: 0.0975 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 76/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3075 - accuracy: 0.0973 - val_loss: 8.3605 - val_accuracy: 0.0980\n",
            "Epoch 77/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2487 - accuracy: 0.0970 - val_loss: 8.3605 - val_accuracy: 0.0958\n",
            "Epoch 78/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3089 - accuracy: 0.0989 - val_loss: 8.3605 - val_accuracy: 0.0958\n",
            "Epoch 79/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3091 - accuracy: 0.0987 - val_loss: 8.3605 - val_accuracy: 0.0958\n",
            "Epoch 80/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3073 - accuracy: 0.0976 - val_loss: 8.3605 - val_accuracy: 0.0958\n",
            "Epoch 81/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 8.3065 - accuracy: 0.0975 - val_loss: 8.3605 - val_accuracy: 0.0958\n",
            "Epoch 82/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 8.3097 - accuracy: 0.0981 - val_loss: 8.3605 - val_accuracy: 0.0958\n",
            "Epoch 83/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3073 - accuracy: 0.0980 - val_loss: 8.3605 - val_accuracy: 0.0958\n",
            "Epoch 84/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3108 - accuracy: 0.0986 - val_loss: 8.3605 - val_accuracy: 0.0958\n",
            "Epoch 85/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3073 - accuracy: 0.0984 - val_loss: 8.3605 - val_accuracy: 0.0958\n",
            "Epoch 86/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3067 - accuracy: 0.0995 - val_loss: 8.3605 - val_accuracy: 0.0958\n",
            "Epoch 87/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3105 - accuracy: 0.0984 - val_loss: 8.3605 - val_accuracy: 0.0958\n",
            "Epoch 88/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.9258 - accuracy: 0.0960 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 89/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8455 - accuracy: 0.0950 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 90/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8793 - accuracy: 0.0971 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 91/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8235 - accuracy: 0.0955 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 92/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8455 - accuracy: 0.0943 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 93/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8861 - accuracy: 0.0950 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 94/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8530 - accuracy: 0.0958 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 95/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8866 - accuracy: 0.0945 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 96/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8960 - accuracy: 0.0962 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 97/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8627 - accuracy: 0.0946 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 98/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8726 - accuracy: 0.0957 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 99/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8296 - accuracy: 0.0934 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 100/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8554 - accuracy: 0.0970 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 101/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8401 - accuracy: 0.0956 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 102/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8278 - accuracy: 0.0955 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 103/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8149 - accuracy: 0.0956 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 104/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8022 - accuracy: 0.0954 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 105/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8549 - accuracy: 0.0964 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 106/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8382 - accuracy: 0.0980 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 107/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8600 - accuracy: 0.0949 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 108/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8358 - accuracy: 0.0965 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 109/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8705 - accuracy: 0.0957 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 110/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8732 - accuracy: 0.0945 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 111/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8616 - accuracy: 0.0958 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 112/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8527 - accuracy: 0.0949 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 113/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8366 - accuracy: 0.0960 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 114/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8350 - accuracy: 0.0951 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 115/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8401 - accuracy: 0.0969 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 116/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8629 - accuracy: 0.0950 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 117/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8603 - accuracy: 0.0949 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 118/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8670 - accuracy: 0.0959 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 119/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8393 - accuracy: 0.0954 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 120/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8425 - accuracy: 0.0947 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 121/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8578 - accuracy: 0.0962 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 122/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8906 - accuracy: 0.0944 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 123/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8621 - accuracy: 0.0941 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 124/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8793 - accuracy: 0.0956 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 125/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8705 - accuracy: 0.0941 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 126/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8675 - accuracy: 0.0955 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 127/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8646 - accuracy: 0.0964 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 128/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 7.8490 - accuracy: 0.0966 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 129/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8573 - accuracy: 0.0935 - val_loss: 7.7576 - val_accuracy: 0.0892\n",
            "Epoch 130/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.8842 - accuracy: 0.0961 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 131/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 8.1114 - accuracy: 0.0988 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 132/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 8.1404 - accuracy: 0.0990 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 133/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1270 - accuracy: 0.0988 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 134/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0472 - accuracy: 0.0989 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 135/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0703 - accuracy: 0.0994 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 136/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1764 - accuracy: 0.0988 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 137/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1756 - accuracy: 0.0991 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 138/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0830 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 139/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1380 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 140/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1262 - accuracy: 0.0990 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 141/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1179 - accuracy: 0.0990 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 142/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0795 - accuracy: 0.0993 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 143/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0983 - accuracy: 0.0994 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 144/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1345 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 145/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1676 - accuracy: 0.0991 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 146/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1206 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 147/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0725 - accuracy: 0.0993 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 148/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0916 - accuracy: 0.0990 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 149/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1055 - accuracy: 0.0990 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 150/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1122 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 151/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1563 - accuracy: 0.0989 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 152/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0542 - accuracy: 0.0990 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 153/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0851 - accuracy: 0.0991 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 154/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1480 - accuracy: 0.0991 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 155/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1200 - accuracy: 0.0993 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 156/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0373 - accuracy: 0.0989 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 157/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1512 - accuracy: 0.0991 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 158/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1292 - accuracy: 0.0993 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 159/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1104 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 160/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1216 - accuracy: 0.0988 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 161/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 8.1458 - accuracy: 0.0993 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 162/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1114 - accuracy: 0.0990 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 163/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0910 - accuracy: 0.0990 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 164/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1286 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 165/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1254 - accuracy: 0.0991 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 166/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1308 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 167/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1071 - accuracy: 0.0991 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 168/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0856 - accuracy: 0.0990 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 169/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1587 - accuracy: 0.0990 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 170/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1477 - accuracy: 0.0990 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 171/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1319 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 172/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1574 - accuracy: 0.0993 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 173/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 8.0999 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 174/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 8.1061 - accuracy: 0.0993 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 175/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1402 - accuracy: 0.0988 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 176/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1442 - accuracy: 0.0991 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 177/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1222 - accuracy: 0.0993 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 178/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1109 - accuracy: 0.0991 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 179/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1386 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 180/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1351 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 181/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1329 - accuracy: 0.0989 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 182/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1555 - accuracy: 0.0991 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 183/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1168 - accuracy: 0.0993 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 184/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0822 - accuracy: 0.0994 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 185/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0897 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 186/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1480 - accuracy: 0.0990 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 187/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1165 - accuracy: 0.0988 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 188/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0824 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 189/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1429 - accuracy: 0.0989 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 190/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1464 - accuracy: 0.0994 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 191/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1106 - accuracy: 0.0994 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 192/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.2060 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 193/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1171 - accuracy: 0.0990 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 194/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1383 - accuracy: 0.0993 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 195/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1284 - accuracy: 0.0989 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 196/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 8.0964 - accuracy: 0.0991 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 197/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1340 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 198/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 8.1023 - accuracy: 0.0991 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 199/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1066 - accuracy: 0.0992 - val_loss: 8.3605 - val_accuracy: 0.1009\n",
            "Epoch 200/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1208 - accuracy: 0.0994 - val_loss: 8.3605 - val_accuracy: 0.1009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model3.compile(optimizer=adam, loss= 'categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "history3 = model3.fit(X_train,y_train,epochs=200,batch_size=128,verbose=True,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBwO9ClSgW_C",
        "outputId": "5c179151-657e-48b0-935d-47ff53864d99"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.1186 - val_accuracy: 0.9802\n",
            "Epoch 2/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.1103 - val_accuracy: 0.9775\n",
            "Epoch 3/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.1096 - val_accuracy: 0.9799\n",
            "Epoch 4/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.1133 - val_accuracy: 0.9809\n",
            "Epoch 5/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.1210 - val_accuracy: 0.9787\n",
            "Epoch 6/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.1094 - val_accuracy: 0.9795\n",
            "Epoch 7/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.1531 - val_accuracy: 0.9781\n",
            "Epoch 8/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1202 - val_accuracy: 0.9802\n",
            "Epoch 9/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.1320 - val_accuracy: 0.9795\n",
            "Epoch 10/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.1190 - val_accuracy: 0.9807\n",
            "Epoch 11/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.1684 - val_accuracy: 0.9794\n",
            "Epoch 12/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1650 - val_accuracy: 0.9786\n",
            "Epoch 13/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.1197 - val_accuracy: 0.9818\n",
            "Epoch 14/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0127 - accuracy: 0.9972 - val_loss: 0.1084 - val_accuracy: 0.9811\n",
            "Epoch 15/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 0.1349 - val_accuracy: 0.9818\n",
            "Epoch 16/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.1268 - val_accuracy: 0.9780\n",
            "Epoch 17/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.1270 - val_accuracy: 0.9832\n",
            "Epoch 18/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.1328 - val_accuracy: 0.9800\n",
            "Epoch 19/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.1750 - val_accuracy: 0.9781\n",
            "Epoch 20/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.1494 - val_accuracy: 0.9792\n",
            "Epoch 21/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.1171 - val_accuracy: 0.9816\n",
            "Epoch 22/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.1488 - val_accuracy: 0.9809\n",
            "Epoch 23/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.2931 - val_accuracy: 0.9738\n",
            "Epoch 24/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.1658 - val_accuracy: 0.9807\n",
            "Epoch 25/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0083 - accuracy: 0.9984 - val_loss: 0.1607 - val_accuracy: 0.9792\n",
            "Epoch 26/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.1445 - val_accuracy: 0.9782\n",
            "Epoch 27/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.1607 - val_accuracy: 0.9814\n",
            "Epoch 28/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.1592 - val_accuracy: 0.9799\n",
            "Epoch 29/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.1491 - val_accuracy: 0.9814\n",
            "Epoch 30/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.1686 - val_accuracy: 0.9829\n",
            "Epoch 31/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.1398 - val_accuracy: 0.9816\n",
            "Epoch 32/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1790 - val_accuracy: 0.9806\n",
            "Epoch 33/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0116 - accuracy: 0.9977 - val_loss: 0.1334 - val_accuracy: 0.9836\n",
            "Epoch 34/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1523 - val_accuracy: 0.9810\n",
            "Epoch 35/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.1269 - val_accuracy: 0.9817\n",
            "Epoch 36/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.1598 - val_accuracy: 0.9817\n",
            "Epoch 37/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.1513 - val_accuracy: 0.9832\n",
            "Epoch 38/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.1531 - val_accuracy: 0.9817\n",
            "Epoch 39/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.1746 - val_accuracy: 0.9828\n",
            "Epoch 40/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.1975 - val_accuracy: 0.9792\n",
            "Epoch 41/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.1470 - val_accuracy: 0.9816\n",
            "Epoch 42/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.2031 - val_accuracy: 0.9831\n",
            "Epoch 43/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.1891 - val_accuracy: 0.9793\n",
            "Epoch 44/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.1658 - val_accuracy: 0.9829\n",
            "Epoch 45/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1832 - val_accuracy: 0.9816\n",
            "Epoch 46/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.2342 - val_accuracy: 0.9784\n",
            "Epoch 47/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.1552 - val_accuracy: 0.9823\n",
            "Epoch 48/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.1678 - val_accuracy: 0.9826\n",
            "Epoch 49/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.1907 - val_accuracy: 0.9778\n",
            "Epoch 50/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.1374 - val_accuracy: 0.9815\n",
            "Epoch 51/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.1927 - val_accuracy: 0.9822\n",
            "Epoch 52/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1767 - val_accuracy: 0.9844\n",
            "Epoch 53/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.2287 - val_accuracy: 0.9813\n",
            "Epoch 54/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.1977 - val_accuracy: 0.9783\n",
            "Epoch 55/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.2313 - val_accuracy: 0.9785\n",
            "Epoch 56/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.2007 - val_accuracy: 0.9809\n",
            "Epoch 57/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.1945 - val_accuracy: 0.9824\n",
            "Epoch 58/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.2018 - val_accuracy: 0.9786\n",
            "Epoch 59/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.2078 - val_accuracy: 0.9829\n",
            "Epoch 60/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.1675 - val_accuracy: 0.9821\n",
            "Epoch 61/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.2064 - val_accuracy: 0.9823\n",
            "Epoch 62/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.2117 - val_accuracy: 0.9820\n",
            "Epoch 63/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 6.1421e-04 - accuracy: 0.9998 - val_loss: 0.2314 - val_accuracy: 0.9853\n",
            "Epoch 64/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.1807 - val_accuracy: 0.9830\n",
            "Epoch 65/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 0.2397 - val_accuracy: 0.9808\n",
            "Epoch 66/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.1919 - val_accuracy: 0.9826\n",
            "Epoch 67/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2523 - val_accuracy: 0.9827\n",
            "Epoch 68/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.1988 - val_accuracy: 0.9805\n",
            "Epoch 69/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.2029 - val_accuracy: 0.9829\n",
            "Epoch 70/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.2193 - val_accuracy: 0.9818\n",
            "Epoch 71/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.2049 - val_accuracy: 0.9833\n",
            "Epoch 72/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.2064 - val_accuracy: 0.9824\n",
            "Epoch 73/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.2741 - val_accuracy: 0.9810\n",
            "Epoch 74/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.1475 - val_accuracy: 0.9812\n",
            "Epoch 75/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.2132 - val_accuracy: 0.9827\n",
            "Epoch 76/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.2045 - val_accuracy: 0.9832\n",
            "Epoch 77/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 5.1812e-04 - accuracy: 0.9999 - val_loss: 0.2840 - val_accuracy: 0.9822\n",
            "Epoch 78/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.2100 - val_accuracy: 0.9823\n",
            "Epoch 79/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.2168 - val_accuracy: 0.9817\n",
            "Epoch 80/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.2432 - val_accuracy: 0.9837\n",
            "Epoch 81/200\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.2546 - val_accuracy: 0.9800\n",
            "Epoch 82/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.1969 - val_accuracy: 0.9832\n",
            "Epoch 83/200\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.1989 - val_accuracy: 0.9810\n",
            "Epoch 84/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.2530 - val_accuracy: 0.9798\n",
            "Epoch 85/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.2823 - val_accuracy: 0.9824\n",
            "Epoch 86/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1875 - val_accuracy: 0.9837\n",
            "Epoch 87/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.2466 - val_accuracy: 0.9842\n",
            "Epoch 88/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 5.7266e-04 - accuracy: 0.9999 - val_loss: 0.2646 - val_accuracy: 0.9813\n",
            "Epoch 89/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.2048 - val_accuracy: 0.9825\n",
            "Epoch 90/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.2066 - val_accuracy: 0.9823\n",
            "Epoch 91/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.2595 - val_accuracy: 0.9845\n",
            "Epoch 92/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 0.2803 - val_accuracy: 0.9799\n",
            "Epoch 93/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.2069 - val_accuracy: 0.9822\n",
            "Epoch 94/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.3026 - val_accuracy: 0.9805\n",
            "Epoch 95/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.2664 - val_accuracy: 0.9823\n",
            "Epoch 96/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.3565 - val_accuracy: 0.9831\n",
            "Epoch 97/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.2093 - val_accuracy: 0.9838\n",
            "Epoch 98/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.2482 - val_accuracy: 0.9829\n",
            "Epoch 99/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.3085 - val_accuracy: 0.9820\n",
            "Epoch 100/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 0.2200 - val_accuracy: 0.9810\n",
            "Epoch 101/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.2587 - val_accuracy: 0.9820\n",
            "Epoch 102/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 3.4026e-04 - accuracy: 0.9999 - val_loss: 0.2451 - val_accuracy: 0.9844\n",
            "Epoch 103/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 1.6232e-05 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9840\n",
            "Epoch 104/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 4.6934e-06 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9839\n",
            "Epoch 105/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 1.0479e-06 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9838\n",
            "Epoch 106/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 6.9171e-07 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9838\n",
            "Epoch 107/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 4.8976e-07 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9840\n",
            "Epoch 108/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 3.5685e-07 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9840\n",
            "Epoch 109/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.6293e-07 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9840\n",
            "Epoch 110/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.9460e-07 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9840\n",
            "Epoch 111/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.4256e-07 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9840\n",
            "Epoch 112/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.0422e-07 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9840\n",
            "Epoch 113/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.7911e-08 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.9840\n",
            "Epoch 114/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 5.9068e-08 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9839\n",
            "Epoch 115/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 4.5058e-08 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.9841\n",
            "Epoch 116/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 3.4244e-08 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9841\n",
            "Epoch 117/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.6255e-08 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9841\n",
            "Epoch 118/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.0186e-08 - accuracy: 1.0000 - val_loss: 0.3210 - val_accuracy: 0.9841\n",
            "Epoch 119/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.5509e-08 - accuracy: 1.0000 - val_loss: 0.3253 - val_accuracy: 0.9841\n",
            "Epoch 120/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.1869e-08 - accuracy: 1.0000 - val_loss: 0.3294 - val_accuracy: 0.9840\n",
            "Epoch 121/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 9.1334e-09 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.9841\n",
            "Epoch 122/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 6.9836e-09 - accuracy: 1.0000 - val_loss: 0.3377 - val_accuracy: 0.9841\n",
            "Epoch 123/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 5.3982e-09 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9840\n",
            "Epoch 124/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 4.1187e-09 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9840\n",
            "Epoch 125/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 3.1769e-09 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9840\n",
            "Epoch 126/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.4517e-09 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9840\n",
            "Epoch 127/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.8994e-09 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9840\n",
            "Epoch 128/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.4961e-09 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.9840\n",
            "Epoch 129/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.1663e-09 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9840\n",
            "Epoch 130/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.9606e-10 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9840\n",
            "Epoch 131/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 7.2718e-10 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.9840\n",
            "Epoch 132/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 5.6426e-10 - accuracy: 1.0000 - val_loss: 0.3740 - val_accuracy: 0.9840\n",
            "Epoch 133/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9840\n",
            "Epoch 134/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 3.4571e-10 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.9840\n",
            "Epoch 135/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.9840\n",
            "Epoch 136/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 2.2054e-10 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.9840\n",
            "Epoch 137/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.6888e-10 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.9840\n",
            "Epoch 138/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.2120e-10 - accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 0.9840\n",
            "Epoch 139/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.0133e-10 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.9840\n",
            "Epoch 140/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.3446e-11 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9838\n",
            "Epoch 141/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 5.9605e-11 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9838\n",
            "Epoch 142/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 4.1723e-11 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.9838\n",
            "Epoch 143/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.5829e-11 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9838\n",
            "Epoch 144/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.1855e-11 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.9839\n",
            "Epoch 145/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.9868e-11 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.9839\n",
            "Epoch 146/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.3908e-11 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.9839\n",
            "Epoch 147/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.1921e-11 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.9839\n",
            "Epoch 148/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.1921e-11 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9839\n",
            "Epoch 149/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 9.9341e-12 - accuracy: 1.0000 - val_loss: 0.4154 - val_accuracy: 0.9839\n",
            "Epoch 150/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 5.9605e-12 - accuracy: 1.0000 - val_loss: 0.4170 - val_accuracy: 0.9839\n",
            "Epoch 151/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 3.9736e-12 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.9839\n",
            "Epoch 152/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 3.9736e-12 - accuracy: 1.0000 - val_loss: 0.4199 - val_accuracy: 0.9839\n",
            "Epoch 153/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.9868e-12 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.9839\n",
            "Epoch 154/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.9839\n",
            "Epoch 155/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.9839\n",
            "Epoch 156/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9839\n",
            "Epoch 157/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.9839\n",
            "Epoch 158/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.9839\n",
            "Epoch 159/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9839\n",
            "Epoch 160/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.9839\n",
            "Epoch 161/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.9839\n",
            "Epoch 162/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.9839\n",
            "Epoch 163/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.9839\n",
            "Epoch 164/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.9839\n",
            "Epoch 165/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.9839\n",
            "Epoch 166/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9839\n",
            "Epoch 167/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9839\n",
            "Epoch 168/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9839\n",
            "Epoch 169/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9839\n",
            "Epoch 170/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4360 - val_accuracy: 0.9839\n",
            "Epoch 171/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.9839\n",
            "Epoch 172/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.9839\n",
            "Epoch 173/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9839\n",
            "Epoch 174/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.9839\n",
            "Epoch 175/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9839\n",
            "Epoch 176/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.9838\n",
            "Epoch 177/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9838\n",
            "Epoch 178/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.9838\n",
            "Epoch 179/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.9838\n",
            "Epoch 180/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4409 - val_accuracy: 0.9838\n",
            "Epoch 181/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.9838\n",
            "Epoch 182/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9838\n",
            "Epoch 183/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.9838\n",
            "Epoch 184/200\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9838\n",
            "Epoch 185/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.9839\n",
            "Epoch 186/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9839\n",
            "Epoch 187/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.9839\n",
            "Epoch 188/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9839\n",
            "Epoch 189/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4443 - val_accuracy: 0.9839\n",
            "Epoch 190/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.9839\n",
            "Epoch 191/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9839\n",
            "Epoch 192/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.9839\n",
            "Epoch 193/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9839\n",
            "Epoch 194/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.9839\n",
            "Epoch 195/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.9839\n",
            "Epoch 196/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.9839\n",
            "Epoch 197/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9839\n",
            "Epoch 198/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.9839\n",
            "Epoch 199/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.9839\n",
            "Epoch 200/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.9839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model4.compile(optimizer=adam, loss= 'categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "history4 = model4.fit(X_train,y_train,epochs=200,batch_size=128,verbose=True,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82HYaAupgZjA",
        "outputId": "410a5133-9164-4945-95f6-f06a262cb3eb"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 8.0234 - accuracy: 0.1039 - val_loss: 7.9301 - val_accuracy: 0.1135\n",
            "Epoch 2/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0564 - accuracy: 0.1072 - val_loss: 7.9301 - val_accuracy: 0.1135\n",
            "Epoch 3/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0072 - accuracy: 0.1075 - val_loss: 7.9301 - val_accuracy: 0.1135\n",
            "Epoch 4/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0497 - accuracy: 0.1066 - val_loss: 7.9301 - val_accuracy: 0.1135\n",
            "Epoch 5/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0002 - accuracy: 0.1056 - val_loss: 7.9301 - val_accuracy: 0.1135\n",
            "Epoch 6/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0671 - accuracy: 0.1067 - val_loss: 7.9301 - val_accuracy: 0.1135\n",
            "Epoch 7/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0717 - accuracy: 0.1057 - val_loss: 7.9301 - val_accuracy: 0.1135\n",
            "Epoch 8/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0950 - accuracy: 0.1055 - val_loss: 8.1880 - val_accuracy: 0.1135\n",
            "Epoch 9/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0728 - accuracy: 0.1022 - val_loss: 7.9301 - val_accuracy: 0.0974\n",
            "Epoch 10/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0209 - accuracy: 0.1004 - val_loss: 7.9301 - val_accuracy: 0.0974\n",
            "Epoch 11/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0625 - accuracy: 0.1021 - val_loss: 7.9301 - val_accuracy: 0.0974\n",
            "Epoch 12/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0859 - accuracy: 0.1014 - val_loss: 7.9301 - val_accuracy: 0.0974\n",
            "Epoch 13/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0410 - accuracy: 0.1021 - val_loss: 7.9301 - val_accuracy: 0.0974\n",
            "Epoch 14/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0634 - accuracy: 0.1005 - val_loss: 7.9301 - val_accuracy: 0.0974\n",
            "Epoch 15/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0985 - accuracy: 0.1008 - val_loss: 7.9301 - val_accuracy: 0.0974\n",
            "Epoch 16/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0456 - accuracy: 0.1023 - val_loss: 7.9301 - val_accuracy: 0.0974\n",
            "Epoch 17/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0709 - accuracy: 0.1017 - val_loss: 7.9301 - val_accuracy: 0.0974\n",
            "Epoch 18/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0676 - accuracy: 0.1012 - val_loss: 7.9301 - val_accuracy: 0.0974\n",
            "Epoch 19/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.0531 - accuracy: 0.1008 - val_loss: 7.9301 - val_accuracy: 0.0974\n",
            "Epoch 20/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 21/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 22/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 23/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 24/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 25/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 26/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 27/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 28/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 29/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 30/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 31/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 32/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 33/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 34/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 35/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 36/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 37/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 38/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 39/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 40/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 41/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 42/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 43/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 44/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 45/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 46/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 47/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 48/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 49/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 50/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 51/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 52/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 53/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 54/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 55/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 56/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 57/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 58/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 59/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 60/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 61/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 62/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 63/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 64/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 65/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 66/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 67/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 68/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 69/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 70/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 71/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 72/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 73/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 74/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 75/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 76/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 77/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 78/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 79/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 80/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 81/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 82/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 83/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 84/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 85/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 86/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 87/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 88/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 89/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 90/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 91/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 92/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 93/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 94/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 95/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 96/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 97/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 98/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 99/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 100/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 101/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 102/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 103/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 104/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 105/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 106/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 107/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 108/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 109/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 110/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 111/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 112/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 113/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 114/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 115/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 116/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 117/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 118/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 119/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 120/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 121/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 122/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 123/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 124/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 125/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 126/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 127/200\n",
            "469/469 [==============================] - 3s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 128/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 129/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 130/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 131/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 132/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 133/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 134/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 135/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 136/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 137/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 138/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 139/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 140/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 141/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 142/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 143/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 144/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 145/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 146/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 147/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 148/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 149/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 150/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 151/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 152/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 153/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 154/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 155/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 156/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 157/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 158/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 159/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 160/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 161/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 162/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 163/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 164/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 165/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 166/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 167/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 168/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 169/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 170/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 171/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 172/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 173/200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 174/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 175/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 176/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 177/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 178/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 179/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 180/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 181/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 182/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 183/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 184/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 185/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 186/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 187/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 188/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 189/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 190/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 191/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 192/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 193/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 194/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 195/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 196/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 197/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 198/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 199/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 200/200\n",
            "469/469 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history1.history['loss'], color = 'red')\n",
        "plt.plot(history2.history['loss'], color='red',linewidth=4.0,alpha=0.3)\n",
        "plt.plot(history3.history['loss'], color = 'blue')\n",
        "plt.plot(history4.history['loss'],color='blue',linewidth=4.0,alpha=0.3)\n",
        "\n",
        "plt.title('Adam opt model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.legend(['Logistic: Xavier ND', 'Logistic: Xavier D', 'RELU:He ND','RELU:He D'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "YKe7dVgSgt2N",
        "outputId": "944b128d-d185-4ad2-b5e4-f247d3eea0ec"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history2.history['val_loss'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5roOpoi7q_Ri",
        "outputId": "3830d605-bdb8-4ed4-cdc0-3e28db73356b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 7.757640838623047, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488, 8.360455513000488]\n"
          ]
        }
      ]
    }
  ]
}