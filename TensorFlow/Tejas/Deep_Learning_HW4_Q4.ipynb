{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4ze6TlaSGWRb7xHww4+Uf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ram130849/Deep_Learning_Systems_Assignments/blob/main/TensorFlow/Tejas/Deep_Learning_HW4_Q4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Home Work 4 \n",
        "\n",
        "References:\n",
        "\n"
      ],
      "metadata": {
        "id": "Kngj1SATd-3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GPU Check"
      ],
      "metadata": {
        "id": "cvh40HtweTg0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uldQLN8Bd6UA"
      },
      "outputs": [],
      "source": [
        "#Path: TensorFlow/Tejas/\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "metadata": {
        "id": "guxcLlYpeV7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "metadata": {
        "id": "VeKf9tbAeXoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dependencies"
      ],
      "metadata": {
        "id": "wj78xNaBeZ_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Model\n",
        "import keras.utils\n",
        "from keras import utils as np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import  Dense, Dropout, Activation, Flatten\n",
        "from librosa.core import stft,istft\n",
        "import soundfile as sf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "IzNqPUpCeb4s"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Data Set\n",
        "\n",
        "We load X_train and X_test from pkl files respectively.\n",
        "\n",
        "\n",
        "\n",
        "1.   But we have to make an empty array of (500,1) for y_train and (200,1) for y_test as they are labels of 1 and 0.\n",
        "2.   1 is label for positive batching (audio signal pairs are utterances of same speaker)\n",
        "\n",
        "1.   0 is for negative batching ( audio signal pairs of different speakers)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0uo4argxeef5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dependencies for Loading data \n",
        "\n",
        "import gzip\n",
        "import pickle\n",
        "import random\n",
        "from itertools import combinations,product"
      ],
      "metadata": {
        "id": "szqpDKiktnwp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLVHSzDWegmI",
        "outputId": "eaa290b8-cbbc-4f4e-c200-108cb92b9571"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/ENGR-E-533 /DATA/HW4/Q4 Speaker Recognition/hw4_trs.pkl', 'rb') as f:\n",
        "    X_train = pickle.load(f)"
      ],
      "metadata": {
        "id": "SiRjqrVieiRY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmAsq0l1evR2",
        "outputId": "0dbffa98-4302-47ff-ab2e-e4ff0da3d823"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 16180)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.zeros((500,1))\n",
        "index=0\n",
        "for i in range(0,50):\n",
        "    for j in range(0,10):\n",
        "        y_train[index]=i\n",
        "        index+=1\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-UkN1L2fFNO",
        "outputId": "aba990ad-866b-4d54-9102-40ca4d8c7e41"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/ENGR-E-533 /DATA/HW4/Q4 Speaker Recognition/hw4_tes.pkl', 'rb') as f:\n",
        "    X_test = pickle.load(f)"
      ],
      "metadata": {
        "id": "ogdSSdCAfJia"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au-nPiMgfLu0",
        "outputId": "ba5707b0-cf06-4865-8322-9051fb2ce2b3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 22631)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.zeros((200,1))\n",
        "idx=0\n",
        "for i in range(0,20):\n",
        "    for j in range(0,10):\n",
        "        y_test[idx]=i\n",
        "        idx+=1\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgY7kvSLfMeE",
        "outputId": "e7f87c6b-e504-4f43-b537-dd4d44508d80"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42u0Uzkow2Sw",
        "outputId": "783e727e-4de4-4ca4-f2bf-51b2fe6c6f1b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.12784029e-05,  2.06392011e-04,  0.00000000e+00, ...,\n",
              "        -9.50228795e-02, -8.75514895e-02, -7.98324272e-02],\n",
              "       [ 0.00000000e+00,  2.19764952e-05,  8.79059808e-05, ...,\n",
              "         1.13178967e-02,  1.05047654e-02,  1.43506527e-02],\n",
              "       [ 1.85077588e-04,  1.48062070e-04,  1.11046553e-04, ...,\n",
              "        -8.95775482e-03, -1.47321764e-02, -2.06546579e-02],\n",
              "       ...,\n",
              "       [ 1.53322384e-04,  1.53322384e-04,  1.53322384e-04, ...,\n",
              "         9.65930894e-03, -1.31857244e-03, -1.06099080e-02],\n",
              "       [ 1.14315364e-04, -1.14315364e-04,  7.62102427e-05, ...,\n",
              "        -1.21555338e-02, -4.95366578e-04,  8.57365225e-03],\n",
              "       [ 3.40873594e-05,  2.04524142e-04,  6.81747188e-05, ...,\n",
              "        -3.63371223e-02, -7.14471042e-02, -9.41492841e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oLeP4fExR6v",
        "outputId": "7faf7839-d837-496f-c991-5b454af308d4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.27267512e-03, -1.81810741e-04,  2.72716105e-04, ...,\n",
              "        -3.63621465e-03, -3.45440372e-03, -4.18164674e-03],\n",
              "       [-2.33645900e-04,  2.33645900e-04,  0.00000000e+00, ...,\n",
              "        -7.00937724e-03, -7.63243251e-03, -9.57948156e-03],\n",
              "       [ 1.45140267e-03, -1.93520362e-04,  2.90280528e-04, ...,\n",
              "        -2.32224423e-03, -2.99956556e-03, -2.61252490e-03],\n",
              "       ...,\n",
              "       [-1.09347195e-04, -1.09347195e-04,  0.00000000e+00, ...,\n",
              "         1.64020795e-03,  1.20281905e-03,  1.20281905e-03],\n",
              "       [ 8.59142674e-05,  0.00000000e+00,  8.59142674e-05, ...,\n",
              "        -1.71828535e-04,  1.11688545e-03,  8.59142689e-04],\n",
              "       [ 8.90608819e-04,  0.00000000e+00,  2.54459679e-04, ...,\n",
              "         1.20868338e-02, -1.41225122e-02,  1.90844748e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Matrix :** (Row:Speaker Number,audio signal)\n",
        "Each speaker has 10 signals (Utterances)\n",
        "\n",
        "\n",
        "*   We have 50 speakers hence 500 rows  ( 50 unique speakers with 10 utterances each)\n",
        "*   Train Speakers have 16180 features per sample.\n",
        "\n",
        "\n",
        "**Test Matrix:** (Row:Speaker Number,audio signal)\n",
        "Each speaker has 10 signals(Utterances)\n",
        "\n",
        "\n",
        "*   We have 20 speakers hence 200 rows  ( 20 unique speakers with 10 utterances each)\n",
        "*   But Test Speakers have more features in the signal: 22631 ( More Rich in data )\n",
        "\n",
        "\n",
        "\n",
        "Resource for random sampling : https://pynative.com/python-random-sample/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wSC2uzNwuOUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STFT of X_train and X_test"
      ],
      "metadata": {
        "id": "J1OxbtV43Iv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L_utterance = 45"
      ],
      "metadata": {
        "id": "kPIbXkws3nq-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_stft = np.zeros(shape=(500,L_utterance,513))\n",
        "for i in range(X_train.shape[0]):\n",
        "    X_data = X_train[i,:]\n",
        "    X_complex = librosa.stft(X_data, n_fft=1024, hop_length=512)\n",
        "    X = np.abs(X_complex).T\n",
        "    X_train_stft[i,:,:] = np.pad(X,((0,13),(0,0)), 'constant') # pas top = 0 , bottom = 13, left = 0 and right = 0 \n",
        "    #pads only bottom of the array because 16810 / 513 = 32 and test data has 45\n",
        "print(X_train_stft.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig3GdWkX3LyZ",
        "outputId": "75e397ca-c525-4a5c-ab8a-f9762431bdcb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 45, 513)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_stft[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ171N4657Xe",
        "outputId": "61605f24-444e-4093-bc57-74562d897776"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02651631, 0.01149094, 0.00238631, ..., 0.00408146, 0.00277443,\n",
              "        0.00204568],\n",
              "       [0.03155294, 0.017131  , 0.00196619, ..., 0.00112135, 0.00039424,\n",
              "        0.00010901],\n",
              "       [0.02640126, 0.01126922, 0.00266385, ..., 0.00064208, 0.00035836,\n",
              "        0.0001147 ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_stft[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMe7mzc051CG",
        "outputId": "ad1e7579-146e-4fe2-8b8b-4bd6335b5ed9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 513)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_stft = np.zeros(shape=(200,45,513))\n",
        "for i in range(X_test.shape[0]):\n",
        "    X_data = X_test[i,:]\n",
        "    X_complex = librosa.stft(X_data, n_fft=1024, hop_length=512)\n",
        "    X = np.abs(X_complex).T\n",
        "    X_test_stft[i,:,:] = X\n",
        "print(X_test_stft.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX3zb-Vr7LpU",
        "outputId": "1476a38e-4c0b-4e40-f500-5296f6c1e3a0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 45, 513)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "na1iIJd57gYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pairing without indexing\n",
        "\n",
        "Encountering an issue with getting data of other speakers in pairs.\n",
        "\n",
        "Hence i follow keras documentation code and use indexing\n",
        "\n",
        "Error at line :   other_speaker_data =X_train[sample for sample in range(500) if sample not in speaker_data_index ]\n",
        "\n",
        "\n",
        "Maybe I can set X_train[:start] + X_train[end:]\n",
        "\n",
        "\n",
        "But after indexing code cause that is a sure shot solution"
      ],
      "metadata": {
        "id": "d5e3VrJE3MC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_speaker = 50\n",
        "speaker_index = 0\n",
        "L_utterance = 45  \n",
        "pair = []      \n",
        "labels =[]\n",
        "for speaker in range(unique_speaker): # used range so that max value of speaker_index will be 49\n",
        "  speaker_data = X_train[speaker * 10 : (speaker+1) * 10 ]\n",
        "  speaker_data_index = np.arange(speaker*10,(speaker+1) * 10,1)\n",
        "  print(speaker_data_index)\n",
        "  other_speaker_data =X_train[sample for sample in range(500) if sample not in speaker_data_index ]\n",
        "  #print(len(speaker_data))\n",
        "  #speaker_index = speaker_index + 1\n",
        "\n",
        "  pos_pairs = random.sample(list(combinations(speaker_data,2)),L_utterance)\n",
        "  #print(pos_pairs)\n",
        "  for pairs in pos_pairs:\n",
        "    x1 = pairs[0]\n",
        "    x2 = pairs[1]\n",
        "    pair += [[x1,x2]]\n",
        "    labels += [1]\n",
        "    #print(pair[0][:])\n",
        "    #print(labels)\n",
        "\n",
        "  #neg_pairs = random.sample(list(combinations(other_speaker_data,speaker_data)))\n",
        "  #neg_pairs = random.sample(list(product(speaker_data,other_speaker_data)),L_utterance)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "MM-Wh4lKuEA1",
        "outputId": "7e089ec7-ea65-4292-fbf4-059c7d3b5501"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-73-8c1edf0bff4b>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    other_speaker_data =X_train[sample for sample in range(500) if sample not in speaker_data_index ]\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pairing with indexing\n",
        "\n"
      ],
      "metadata": {
        "id": "n-gP219jBtff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L_utterance = 45"
      ],
      "metadata": {
        "id": "qLLrksgPGsw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code follows structure given in https://keras.io/examples/vision/siamese_contrastive/\n",
        "\n",
        "L_utterance = 45\n",
        "y_train = np.array(y_train)\n",
        "X_index = np.arange(0,len(y_train)).reshape(-1,1)\n",
        "unique_speaker = np.unique(y_train)\n",
        "pairs = []\n",
        "labels =[]\n",
        "\n",
        "for speaker in unique_speaker:\n",
        "  speaker_index = X_index[np.where(y_train==speaker)]\n",
        "  other_speaker_index = X_index[np.where(y_train!=speaker)]\n",
        "\n",
        "  L_pos_list = list(combinations(speaker_index,2))\n",
        "  L_pos_pairs = random.sample( L_pos_list,L_utterance)\n",
        "  for pair in L_pos_pairs:\n",
        "    sample1 = X_train_stft[pair[0],:,:]\n",
        "    sample2 = X_train_stft[pair[1],:,:]\n",
        "    pairs = pairs + [[sample1,sample2]]\n",
        "    labels = labels + [1]\n",
        "\n",
        "  L_neg_pairs = list(product(speaker_index,other_speaker_index))\n",
        "  L_neg_pairs = random.sample( L_neg_pairs,L_utterance)\n",
        "  for pair in L_neg_pairs:\n",
        "    neg_sample1 = X_train_stft[pair[0],:,:]\n",
        "    neg_sample2 = X_train_stft[pair[1],:,:]\n",
        "    pairs = pairs + [[neg_sample1,neg_sample2]]\n",
        "    labels = labels + [0]\n",
        "\n",
        "pair = np.asarray(pairs)\n",
        "label = np.asarray(labels).astype(\"float32\")"
      ],
      "metadata": {
        "id": "2rMGoCuaBskn"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pair.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0zviyh9N2yD",
        "outputId": "53a5b6df-3c7b-4e92-857c-4014330c6ab9"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4500, 2, 45, 513)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60N_3JQiSxcf",
        "outputId": "e4162fae-65e2-453a-e822-334e88cef24d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4500,)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pair.shape = (4500, 2, 45, 513)\n",
        "\n",
        "We have 4500 pairs\n",
        "Each pair contains 2 samples\n",
        "each sample shape is (45,513)\n",
        "\n",
        "L_utterance is 45 hence we have a 2L batch of 90 size\n",
        "\n",
        "\n",
        "50 of such speakers hence we have 90*50 = 4500 pairs"
      ],
      "metadata": {
        "id": "cAMnnEO9Tup8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code follows structure given in https://keras.io/examples/vision/siamese_contrastive/\n",
        "\n",
        "L_utterance = 45\n",
        "y_train = np.array(y_test)\n",
        "X_index = np.arange(0,len(y_test)).reshape(-1,1)\n",
        "unique_speaker = np.unique(y_test)\n",
        "testpairs = []\n",
        "testlabels =[]\n",
        "\n",
        "for speaker in unique_speaker:\n",
        "  speaker_index = X_index[np.where(y_train==speaker)]\n",
        "  other_speaker_index = X_index[np.where(y_train!=speaker)]\n",
        "\n",
        "  L_pos_list = list(combinations(speaker_index,2))\n",
        "  L_pos_pairs = random.sample( L_pos_list,L_utterance)\n",
        "  for pair in L_pos_pairs:\n",
        "    sample1 = X_test_stft[pair[0],:,:]\n",
        "    sample2 = X_test_stft[pair[1],:,:]\n",
        "    testpairs = testpairs + [[sample1,sample2]]\n",
        "    testlabels = testlabels + [1]\n",
        "\n",
        "  L_neg_pairs = list(product(speaker_index,other_speaker_index))\n",
        "  L_neg_pairs = random.sample( L_neg_pairs,L_utterance)\n",
        "  for pair in L_neg_pairs:\n",
        "    neg_sample1 = X_test_stft[pair[0],:,:]\n",
        "    neg_sample2 = X_test_stft[pair[1],:,:]\n",
        "    testpairs = testpairs + [[neg_sample1,neg_sample2]]\n",
        "    testlabels = testlabels + [0]\n",
        "\n",
        "testpair = np.asarray(testpairs)\n",
        "testlabel = np.asarray(testlabels).astype(\"float32\")"
      ],
      "metadata": {
        "id": "0TfvPVNWTCz7"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testpair.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a19IO1zQWXN1",
        "outputId": "ce60cd23-3acb-4b33-d3e1-3fa9bf3974ae"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1800, 2, 45, 513)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testlabel.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lreEnMndWZDB",
        "outputId": "95036d64-de22-4d51-aa90-3569dc59c838"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1800,)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(testpair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znKiV7GDlpRk",
        "outputId": "22bdf6ba-d960-46db-882c-ca48901c7360"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pair.shape = (4500, 2, 45, 513)\n",
        "\n",
        "We have 4500 pairs\n",
        "Each pair contains 2 samples\n",
        "each sample shape is (45,513)\n",
        "\n",
        "L_utterance is 45 hence we have a 2L batch of 90 size\n",
        "\n",
        "\n",
        "50 of such speakers hence we have 90*50 = 4500 pairs"
      ],
      "metadata": {
        "id": "xxRNRur5Xk2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference : https://keras.io/examples/vision/siamese_contrastive/\n",
        "def euclidean_distance(vects):\n",
        "    \"\"\"Find the Euclidean distance between two vectors.\n",
        "\n",
        "    Arguments:\n",
        "        vects: List containing two tensors of same length.\n",
        "\n",
        "    Returns:\n",
        "        Tensor containing euclidean distance\n",
        "        (as floating point value) between vectors.\n",
        "    \"\"\"\n",
        "\n",
        "    x, y = vects\n",
        "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
        "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n"
      ],
      "metadata": {
        "id": "XJFhfQKbWeVr"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ref: #Reference : https://keras.io/examples/vision/siamese_contrastive/ \n",
        "#and https://towardsdatascience.com/siamese-networks-introduction-and-implementation-2140e3443dee\n",
        "\n",
        "\n",
        "input = layers.Input(shape=(45,513))\n",
        "x = tf.keras.layers.GRU(513, return_sequences=True,dropout=0.1, name = \"layer1\")(input),\n",
        "x = tf.keras.layers.GRU(513, return_sequences=True,dropout=0.2, name = \"layer2\")(x[0]),\n",
        "x = tf.keras.layers.GRU(513, return_sequences=False,dropout=0.2, name = \"layer3\")(x[0]),\n",
        "x = tf.keras.layers.Dense(256,activation = 'relu', name = \"Denselayer1\")(x[0]),\n",
        "x = tf.keras.layers.Dense(64,activation = 'relu', name = \"Denselayer2\")(x[0])\n",
        "\n",
        "embedding_network = tf.keras.Model(input, x)\n",
        "\n",
        "ip1 = layers.Input((45,513))\n",
        "ip2 = layers.Input((45,513))\n",
        "\n",
        "left_model = embedding_network(ip1)\n",
        "right_model = embedding_network(ip2)\n",
        "\n",
        "x2 = tf.keras.layers.Lambda(euclidean_distance)([left_model, right_model])\n",
        "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x2)\n",
        "siamesemodel = tf.keras.Model(inputs=[ip1, ip2], outputs=output)"
      ],
      "metadata": {
        "id": "TvxmyY8SeOE4"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(margin=1):\n",
        "    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n",
        "    Returns:\n",
        "        'constrastive_loss' function with data ('margin') attached.\n",
        "    \"\"\"\n",
        "\n",
        "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
        "    #                         true_value * square( max(margin-prediction, 0) ))\n",
        "    def contrastive_loss(y_true, y_pred):\n",
        "        \"\"\"Calculates the constrastive loss.\n",
        "\n",
        "        Arguments:\n",
        "            y_true: List of labels, each label is of type float32.\n",
        "            y_pred: List of predictions of same length as of y_true,\n",
        "                    each label is of type float32.\n",
        "\n",
        "        Returns:\n",
        "            A tensor containing constrastive loss as floating point value.\n",
        "        \"\"\"\n",
        "\n",
        "        square_pred = tf.math.square(y_pred)\n",
        "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
        "        return tf.math.reduce_mean(\n",
        "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
        "        )\n",
        "\n",
        "    return contrastive_loss"
      ],
      "metadata": {
        "id": "ucthtRqEh_OU"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamesemodel.compile(loss=loss(margin=1), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "siamesemodel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXLJlsw6jquz",
        "outputId": "0eda0d82-a0b6-4e67-8f29-91a42b8a0b2c"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, 45, 513)]    0           []                               \n",
            "                                                                                                  \n",
            " input_12 (InputLayer)          [(None, 45, 513)]    0           []                               \n",
            "                                                                                                  \n",
            " model_6 (Functional)           (None, 64)           4894308     ['input_11[0][0]',               \n",
            "                                                                  'input_12[0][0]']               \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1)            0           ['model_6[0][0]',                \n",
            "                                                                  'model_6[1][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 1)            2           ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,894,310\n",
            "Trainable params: 4,894,310\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYEhuwhamz29",
        "outputId": "f2ef65e6-962b-4032-ecee-8308f50df995"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(190, 188)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = siamesemodel.fit(\n",
        "    [pair[:,0], pair[:,1]],\n",
        "    label,\n",
        "    validation_data=([testpair[:,0],testpair[:,1]],testlabel),\n",
        "    batch_size=90,\n",
        "    epochs=30\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "nTNgLrCxkQD6",
        "outputId": "a79b38f2-d269-4164-ed93-e31c2cf08820"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-d9d8fe42edf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = siamesemodel.fit(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
          ]
        }
      ]
    }
  ]
}